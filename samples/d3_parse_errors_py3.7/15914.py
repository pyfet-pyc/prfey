# decompyle3 version 3.7.5
# Python bytecode 3.7 (3394)
# Decompiled from: Python 3.8.11 (default, Aug 17 2021, 15:56:41) 
# [GCC 10.2.1 20210110]
# Embedded file name: site-packages\youtube_dl\utils.py
from __future__ import unicode_literals
import base64, binascii, calendar, codecs, collections, contextlib, ctypes, datetime, email.utils, email.header, errno, functools, gzip, io, itertools, json, locale, math, operator, os, platform, random, re, socket, ssl, subprocess, sys, tempfile, time, traceback, xml.etree.ElementTree, zlib
from .compat import compat_HTMLParseError, compat_HTMLParser, compat_basestring, compat_chr, compat_cookiejar, compat_ctypes_WINFUNCTYPE, compat_etree_fromstring, compat_expanduser, compat_html_entities, compat_html_entities_html5, compat_http_client, compat_integer_types, compat_kwargs, compat_os_name, compat_parse_qs, compat_shlex_quote, compat_str, compat_struct_pack, compat_struct_unpack, compat_urllib_error, compat_urllib_parse, compat_urllib_parse_urlencode, compat_urllib_parse_urlparse, compat_urllib_parse_unquote_plus, compat_urllib_request, compat_urlparse, compat_xpath
from .socks import ProxyType, sockssocket

def register_socks_protocols():
    for scheme in ('socks', 'socks4', 'socks4a', 'socks5'):
        if scheme not in compat_urlparse.uses_netloc:
            compat_urlparse.uses_netloc.append(scheme)


compiled_regex_type = type(re.compile(''))

def random_user_agent():
    _USER_AGENT_TPL = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/%s Safari/537.36'
    _CHROME_VERSIONS = ('74.0.3729.129', '76.0.3780.3', '76.0.3780.2', '74.0.3729.128',
                        '76.0.3780.1', '76.0.3780.0', '75.0.3770.15', '74.0.3729.127',
                        '74.0.3729.126', '76.0.3779.1', '76.0.3779.0', '75.0.3770.14',
                        '74.0.3729.125', '76.0.3778.1', '76.0.3778.0', '75.0.3770.13',
                        '74.0.3729.124', '74.0.3729.123', '73.0.3683.121', '76.0.3777.1',
                        '76.0.3777.0', '75.0.3770.12', '74.0.3729.122', '76.0.3776.4',
                        '75.0.3770.11', '74.0.3729.121', '76.0.3776.3', '76.0.3776.2',
                        '73.0.3683.120', '74.0.3729.120', '74.0.3729.119', '74.0.3729.118',
                        '76.0.3776.1', '76.0.3776.0', '76.0.3775.5', '75.0.3770.10',
                        '74.0.3729.117', '76.0.3775.4', '76.0.3775.3', '74.0.3729.116',
                        '75.0.3770.9', '76.0.3775.2', '76.0.3775.1', '76.0.3775.0',
                        '75.0.3770.8', '74.0.3729.115', '74.0.3729.114', '76.0.3774.1',
                        '76.0.3774.0', '75.0.3770.7', '74.0.3729.113', '74.0.3729.112',
                        '74.0.3729.111', '76.0.3773.1', '76.0.3773.0', '75.0.3770.6',
                        '74.0.3729.110', '74.0.3729.109', '76.0.3772.1', '76.0.3772.0',
                        '75.0.3770.5', '74.0.3729.108', '74.0.3729.107', '76.0.3771.1',
                        '76.0.3771.0', '75.0.3770.4', '74.0.3729.106', '74.0.3729.105',
                        '75.0.3770.3', '74.0.3729.104', '74.0.3729.103', '74.0.3729.102',
                        '75.0.3770.2', '74.0.3729.101', '75.0.3770.1', '75.0.3770.0',
                        '74.0.3729.100', '75.0.3769.5', '75.0.3769.4', '74.0.3729.99',
                        '75.0.3769.3', '75.0.3769.2', '75.0.3768.6', '74.0.3729.98',
                        '75.0.3769.1', '75.0.3769.0', '74.0.3729.97', '73.0.3683.119',
                        '73.0.3683.118', '74.0.3729.96', '75.0.3768.5', '75.0.3768.4',
                        '75.0.3768.3', '75.0.3768.2', '74.0.3729.95', '74.0.3729.94',
                        '75.0.3768.1', '75.0.3768.0', '74.0.3729.93', '74.0.3729.92',
                        '73.0.3683.117', '74.0.3729.91', '75.0.3766.3', '74.0.3729.90',
                        '75.0.3767.2', '75.0.3767.1', '75.0.3767.0', '74.0.3729.89',
                        '73.0.3683.116', '75.0.3766.2', '74.0.3729.88', '75.0.3766.1',
                        '75.0.3766.0', '74.0.3729.87', '73.0.3683.115', '74.0.3729.86',
                        '75.0.3765.1', '75.0.3765.0', '74.0.3729.85', '73.0.3683.114',
                        '74.0.3729.84', '75.0.3764.1', '75.0.3764.0', '74.0.3729.83',
                        '73.0.3683.113', '75.0.3763.2', '75.0.3761.4', '74.0.3729.82',
                        '75.0.3763.1', '75.0.3763.0', '74.0.3729.81', '73.0.3683.112',
                        '75.0.3762.1', '75.0.3762.0', '74.0.3729.80', '75.0.3761.3',
                        '74.0.3729.79', '73.0.3683.111', '75.0.3761.2', '74.0.3729.78',
                        '74.0.3729.77', '75.0.3761.1', '75.0.3761.0', '73.0.3683.110',
                        '74.0.3729.76', '74.0.3729.75', '75.0.3760.0', '74.0.3729.74',
                        '75.0.3759.8', '75.0.3759.7', '75.0.3759.6', '74.0.3729.73',
                        '75.0.3759.5', '74.0.3729.72', '73.0.3683.109', '75.0.3759.4',
                        '75.0.3759.3', '74.0.3729.71', '75.0.3759.2', '74.0.3729.70',
                        '73.0.3683.108', '74.0.3729.69', '75.0.3759.1', '75.0.3759.0',
                        '74.0.3729.68', '73.0.3683.107', '74.0.3729.67', '75.0.3758.1',
                        '75.0.3758.0', '74.0.3729.66', '73.0.3683.106', '74.0.3729.65',
                        '75.0.3757.1', '75.0.3757.0', '74.0.3729.64', '73.0.3683.105',
                        '74.0.3729.63', '75.0.3756.1', '75.0.3756.0', '74.0.3729.62',
                        '73.0.3683.104', '75.0.3755.3', '75.0.3755.2', '73.0.3683.103',
                        '75.0.3755.1', '75.0.3755.0', '74.0.3729.61', '73.0.3683.102',
                        '74.0.3729.60', '75.0.3754.2', '74.0.3729.59', '75.0.3753.4',
                        '74.0.3729.58', '75.0.3754.1', '75.0.3754.0', '74.0.3729.57',
                        '73.0.3683.101', '75.0.3753.3', '75.0.3752.2', '75.0.3753.2',
                        '74.0.3729.56', '75.0.3753.1', '75.0.3753.0', '74.0.3729.55',
                        '73.0.3683.100', '74.0.3729.54', '75.0.3752.1', '75.0.3752.0',
                        '74.0.3729.53', '73.0.3683.99', '74.0.3729.52', '75.0.3751.1',
                        '75.0.3751.0', '74.0.3729.51', '73.0.3683.98', '74.0.3729.50',
                        '75.0.3750.0', '74.0.3729.49', '74.0.3729.48', '74.0.3729.47',
                        '75.0.3749.3', '74.0.3729.46', '73.0.3683.97', '75.0.3749.2',
                        '74.0.3729.45', '75.0.3749.1', '75.0.3749.0', '74.0.3729.44',
                        '73.0.3683.96', '74.0.3729.43', '74.0.3729.42', '75.0.3748.1',
                        '75.0.3748.0', '74.0.3729.41', '75.0.3747.1', '73.0.3683.95',
                        '75.0.3746.4', '74.0.3729.40', '74.0.3729.39', '75.0.3747.0',
                        '75.0.3746.3', '75.0.3746.2', '74.0.3729.38', '75.0.3746.1',
                        '75.0.3746.0', '74.0.3729.37', '73.0.3683.94', '75.0.3745.5',
                        '75.0.3745.4', '75.0.3745.3', '75.0.3745.2', '74.0.3729.36',
                        '75.0.3745.1', '75.0.3745.0', '75.0.3744.2', '74.0.3729.35',
                        '73.0.3683.93', '74.0.3729.34', '75.0.3744.1', '75.0.3744.0',
                        '74.0.3729.33', '73.0.3683.92', '74.0.3729.32', '74.0.3729.31',
                        '73.0.3683.91', '75.0.3741.2', '75.0.3740.5', '74.0.3729.30',
                        '75.0.3741.1', '75.0.3741.0', '74.0.3729.29', '75.0.3740.4',
                        '73.0.3683.90', '74.0.3729.28', '75.0.3740.3', '73.0.3683.89',
                        '75.0.3740.2', '74.0.3729.27', '75.0.3740.1', '75.0.3740.0',
                        '74.0.3729.26', '73.0.3683.88', '73.0.3683.87', '74.0.3729.25',
                        '75.0.3739.1', '75.0.3739.0', '73.0.3683.86', '74.0.3729.24',
                        '73.0.3683.85', '75.0.3738.4', '75.0.3738.3', '75.0.3738.2',
                        '75.0.3738.1', '75.0.3738.0', '74.0.3729.23', '73.0.3683.84',
                        '74.0.3729.22', '74.0.3729.21', '75.0.3737.1', '75.0.3737.0',
                        '74.0.3729.20', '73.0.3683.83', '74.0.3729.19', '75.0.3736.1',
                        '75.0.3736.0', '74.0.3729.18', '73.0.3683.82', '74.0.3729.17',
                        '75.0.3735.1', '75.0.3735.0', '74.0.3729.16', '73.0.3683.81',
                        '75.0.3734.1', '75.0.3734.0', '74.0.3729.15', '73.0.3683.80',
                        '74.0.3729.14', '75.0.3733.1', '75.0.3733.0', '75.0.3732.1',
                        '74.0.3729.13', '74.0.3729.12', '73.0.3683.79', '74.0.3729.11',
                        '75.0.3732.0', '74.0.3729.10', '73.0.3683.78', '74.0.3729.9',
                        '74.0.3729.8', '74.0.3729.7', '75.0.3731.3', '75.0.3731.2',
                        '75.0.3731.0', '74.0.3729.6', '73.0.3683.77', '73.0.3683.76',
                        '75.0.3730.5', '75.0.3730.4', '73.0.3683.75', '74.0.3729.5',
                        '73.0.3683.74', '75.0.3730.3', '75.0.3730.2', '74.0.3729.4',
                        '73.0.3683.73', '73.0.3683.72', '75.0.3730.1', '75.0.3730.0',
                        '74.0.3729.3', '73.0.3683.71', '74.0.3729.2', '73.0.3683.70',
                        '74.0.3729.1', '74.0.3729.0', '74.0.3726.4', '73.0.3683.69',
                        '74.0.3726.3', '74.0.3728.0', '74.0.3726.2', '73.0.3683.68',
                        '74.0.3726.1', '74.0.3726.0', '74.0.3725.4', '73.0.3683.67',
                        '73.0.3683.66', '74.0.3725.3', '74.0.3725.2', '74.0.3725.1',
                        '74.0.3724.8', '74.0.3725.0', '73.0.3683.65', '74.0.3724.7',
                        '74.0.3724.6', '74.0.3724.5', '74.0.3724.4', '74.0.3724.3',
                        '74.0.3724.2', '74.0.3724.1', '74.0.3724.0', '73.0.3683.64',
                        '74.0.3723.1', '74.0.3723.0', '73.0.3683.63', '74.0.3722.1',
                        '74.0.3722.0', '73.0.3683.62', '74.0.3718.9', '74.0.3702.3',
                        '74.0.3721.3', '74.0.3721.2', '74.0.3721.1', '74.0.3721.0',
                        '74.0.3720.6', '73.0.3683.61', '72.0.3626.122', '73.0.3683.60',
                        '74.0.3720.5', '72.0.3626.121', '74.0.3718.8', '74.0.3720.4',
                        '74.0.3720.3', '74.0.3718.7', '74.0.3720.2', '74.0.3720.1',
                        '74.0.3720.0', '74.0.3718.6', '74.0.3719.5', '73.0.3683.59',
                        '74.0.3718.5', '74.0.3718.4', '74.0.3719.4', '74.0.3719.3',
                        '74.0.3719.2', '74.0.3719.1', '73.0.3683.58', '74.0.3719.0',
                        '73.0.3683.57', '73.0.3683.56', '74.0.3718.3', '73.0.3683.55',
                        '74.0.3718.2', '74.0.3718.1', '74.0.3718.0', '73.0.3683.54',
                        '74.0.3717.2', '73.0.3683.53', '74.0.3717.1', '74.0.3717.0',
                        '73.0.3683.52', '74.0.3716.1', '74.0.3716.0', '73.0.3683.51',
                        '74.0.3715.1', '74.0.3715.0', '73.0.3683.50', '74.0.3711.2',
                        '74.0.3714.2', '74.0.3713.3', '74.0.3714.1', '74.0.3714.0',
                        '73.0.3683.49', '74.0.3713.1', '74.0.3713.0', '72.0.3626.120',
                        '73.0.3683.48', '74.0.3712.2', '74.0.3712.1', '74.0.3712.0',
                        '73.0.3683.47', '72.0.3626.119', '73.0.3683.46', '74.0.3710.2',
                        '72.0.3626.118', '74.0.3711.1', '74.0.3711.0', '73.0.3683.45',
                        '72.0.3626.117', '74.0.3710.1', '74.0.3710.0', '73.0.3683.44',
                        '72.0.3626.116', '74.0.3709.1', '74.0.3709.0', '74.0.3704.9',
                        '73.0.3683.43', '72.0.3626.115', '74.0.3704.8', '74.0.3704.7',
                        '74.0.3708.0', '74.0.3706.7', '74.0.3704.6', '73.0.3683.42',
                        '72.0.3626.114', '74.0.3706.6', '72.0.3626.113', '74.0.3704.5',
                        '74.0.3706.5', '74.0.3706.4', '74.0.3706.3', '74.0.3706.2',
                        '74.0.3706.1', '74.0.3706.0', '73.0.3683.41', '72.0.3626.112',
                        '74.0.3705.1', '74.0.3705.0', '73.0.3683.40', '72.0.3626.111',
                        '73.0.3683.39', '74.0.3704.4', '73.0.3683.38', '74.0.3704.3',
                        '74.0.3704.2', '74.0.3704.1', '74.0.3704.0', '73.0.3683.37',
                        '72.0.3626.110', '72.0.3626.109', '74.0.3703.3', '74.0.3703.2',
                        '73.0.3683.36', '74.0.3703.1', '74.0.3703.0', '73.0.3683.35',
                        '72.0.3626.108', '74.0.3702.2', '74.0.3699.3', '74.0.3702.1',
                        '74.0.3702.0', '73.0.3683.34', '72.0.3626.107', '73.0.3683.33',
                        '74.0.3701.1', '74.0.3701.0', '73.0.3683.32', '73.0.3683.31',
                        '72.0.3626.105', '74.0.3700.1', '74.0.3700.0', '73.0.3683.29',
                        '72.0.3626.103', '74.0.3699.2', '74.0.3699.1', '74.0.3699.0',
                        '73.0.3683.28', '72.0.3626.102', '73.0.3683.27', '73.0.3683.26',
                        '74.0.3698.0', '74.0.3696.2', '72.0.3626.101', '73.0.3683.25',
                        '74.0.3696.1', '74.0.3696.0', '74.0.3694.8', '72.0.3626.100',
                        '74.0.3694.7', '74.0.3694.6', '74.0.3694.5', '74.0.3694.4',
                        '72.0.3626.99', '72.0.3626.98', '74.0.3694.3', '73.0.3683.24',
                        '72.0.3626.97', '72.0.3626.96', '72.0.3626.95', '73.0.3683.23',
                        '72.0.3626.94', '73.0.3683.22', '73.0.3683.21', '72.0.3626.93',
                        '74.0.3694.2', '72.0.3626.92', '74.0.3694.1', '74.0.3694.0',
                        '74.0.3693.6', '73.0.3683.20', '72.0.3626.91', '74.0.3693.5',
                        '74.0.3693.4', '74.0.3693.3', '74.0.3693.2', '73.0.3683.19',
                        '74.0.3693.1', '74.0.3693.0', '73.0.3683.18', '72.0.3626.90',
                        '74.0.3692.1', '74.0.3692.0', '73.0.3683.17', '72.0.3626.89',
                        '74.0.3687.3', '74.0.3691.1', '74.0.3691.0', '73.0.3683.16',
                        '72.0.3626.88', '72.0.3626.87', '73.0.3683.15', '74.0.3690.1',
                        '74.0.3690.0', '73.0.3683.14', '72.0.3626.86', '73.0.3683.13',
                        '73.0.3683.12', '74.0.3689.1', '74.0.3689.0', '73.0.3683.11',
                        '72.0.3626.85', '73.0.3683.10', '72.0.3626.84', '73.0.3683.9',
                        '74.0.3688.1', '74.0.3688.0', '73.0.3683.8', '72.0.3626.83',
                        '74.0.3687.2', '74.0.3687.1', '74.0.3687.0', '73.0.3683.7',
                        '72.0.3626.82', '74.0.3686.4', '72.0.3626.81', '74.0.3686.3',
                        '74.0.3686.2', '74.0.3686.1', '74.0.3686.0', '73.0.3683.6',
                        '72.0.3626.80', '74.0.3685.1', '74.0.3685.0', '73.0.3683.5',
                        '72.0.3626.79', '74.0.3684.1', '74.0.3684.0', '73.0.3683.4',
                        '72.0.3626.78', '72.0.3626.77', '73.0.3683.3', '73.0.3683.2',
                        '72.0.3626.76', '73.0.3683.1', '73.0.3683.0', '72.0.3626.75',
                        '71.0.3578.141', '73.0.3682.1', '73.0.3682.0', '72.0.3626.74',
                        '71.0.3578.140', '73.0.3681.4', '73.0.3681.3', '73.0.3681.2',
                        '73.0.3681.1', '73.0.3681.0', '72.0.3626.73', '71.0.3578.139',
                        '72.0.3626.72', '72.0.3626.71', '73.0.3680.1', '73.0.3680.0',
                        '72.0.3626.70', '71.0.3578.138', '73.0.3678.2', '73.0.3679.1',
                        '73.0.3679.0', '72.0.3626.69', '71.0.3578.137', '73.0.3678.1',
                        '73.0.3678.0', '71.0.3578.136', '73.0.3677.1', '73.0.3677.0',
                        '72.0.3626.68', '72.0.3626.67', '71.0.3578.135', '73.0.3676.1',
                        '73.0.3676.0', '73.0.3674.2', '72.0.3626.66', '71.0.3578.134',
                        '73.0.3674.1', '73.0.3674.0', '72.0.3626.65', '71.0.3578.133',
                        '73.0.3673.2', '73.0.3673.1', '73.0.3673.0', '72.0.3626.64',
                        '71.0.3578.132', '72.0.3626.63', '72.0.3626.62', '72.0.3626.61',
                        '72.0.3626.60', '73.0.3672.1', '73.0.3672.0', '72.0.3626.59',
                        '71.0.3578.131', '73.0.3671.3', '73.0.3671.2', '73.0.3671.1',
                        '73.0.3671.0', '72.0.3626.58', '71.0.3578.130', '73.0.3670.1',
                        '73.0.3670.0', '72.0.3626.57', '71.0.3578.129', '73.0.3669.1',
                        '73.0.3669.0', '72.0.3626.56', '71.0.3578.128', '73.0.3668.2',
                        '73.0.3668.1', '73.0.3668.0', '72.0.3626.55', '71.0.3578.127',
                        '73.0.3667.2', '73.0.3667.1', '73.0.3667.0', '72.0.3626.54',
                        '71.0.3578.126', '73.0.3666.1', '73.0.3666.0', '72.0.3626.53',
                        '71.0.3578.125', '73.0.3665.4', '73.0.3665.3', '72.0.3626.52',
                        '73.0.3665.2', '73.0.3664.4', '73.0.3665.1', '73.0.3665.0',
                        '72.0.3626.51', '71.0.3578.124', '72.0.3626.50', '73.0.3664.3',
                        '73.0.3664.2', '73.0.3664.1', '73.0.3664.0', '73.0.3663.2',
                        '72.0.3626.49', '71.0.3578.123', '73.0.3663.1', '73.0.3663.0',
                        '72.0.3626.48', '71.0.3578.122', '73.0.3662.1', '73.0.3662.0',
                        '72.0.3626.47', '71.0.3578.121', '73.0.3661.1', '72.0.3626.46',
                        '73.0.3661.0', '72.0.3626.45', '71.0.3578.120', '73.0.3660.2',
                        '73.0.3660.1', '73.0.3660.0', '72.0.3626.44', '71.0.3578.119',
                        '73.0.3659.1', '73.0.3659.0', '72.0.3626.43', '71.0.3578.118',
                        '73.0.3658.1', '73.0.3658.0', '72.0.3626.42', '71.0.3578.117',
                        '73.0.3657.1', '73.0.3657.0', '72.0.3626.41', '71.0.3578.116',
                        '73.0.3656.1', '73.0.3656.0', '72.0.3626.40', '71.0.3578.115',
                        '73.0.3655.1', '73.0.3655.0', '72.0.3626.39', '71.0.3578.114',
                        '73.0.3654.1', '73.0.3654.0', '72.0.3626.38', '71.0.3578.113',
                        '73.0.3653.1', '73.0.3653.0', '72.0.3626.37', '71.0.3578.112',
                        '73.0.3652.1', '73.0.3652.0', '72.0.3626.36', '71.0.3578.111',
                        '73.0.3651.1', '73.0.3651.0', '72.0.3626.35', '71.0.3578.110',
                        '73.0.3650.1', '73.0.3650.0', '72.0.3626.34', '71.0.3578.109',
                        '73.0.3649.1', '73.0.3649.0', '72.0.3626.33', '71.0.3578.108',
                        '73.0.3648.2', '73.0.3648.1', '73.0.3648.0', '72.0.3626.32',
                        '71.0.3578.107', '73.0.3647.2', '73.0.3647.1', '73.0.3647.0',
                        '72.0.3626.31', '71.0.3578.106', '73.0.3635.3', '73.0.3646.2',
                        '73.0.3646.1', '73.0.3646.0', '72.0.3626.30', '71.0.3578.105',
                        '72.0.3626.29', '73.0.3645.2', '73.0.3645.1', '73.0.3645.0',
                        '72.0.3626.28', '71.0.3578.104', '72.0.3626.27', '72.0.3626.26',
                        '72.0.3626.25', '72.0.3626.24', '73.0.3644.0', '73.0.3643.2',
                        '72.0.3626.23', '71.0.3578.103', '73.0.3643.1', '73.0.3643.0',
                        '72.0.3626.22', '71.0.3578.102', '73.0.3642.1', '73.0.3642.0',
                        '72.0.3626.21', '71.0.3578.101', '73.0.3641.1', '73.0.3641.0',
                        '72.0.3626.20', '71.0.3578.100', '72.0.3626.19', '73.0.3640.1',
                        '73.0.3640.0', '72.0.3626.18', '73.0.3639.1', '71.0.3578.99',
                        '73.0.3639.0', '72.0.3626.17', '73.0.3638.2', '72.0.3626.16',
                        '73.0.3638.1', '73.0.3638.0', '72.0.3626.15', '71.0.3578.98',
                        '73.0.3635.2', '71.0.3578.97', '73.0.3637.1', '73.0.3637.0',
                        '72.0.3626.14', '71.0.3578.96', '71.0.3578.95', '72.0.3626.13',
                        '71.0.3578.94', '73.0.3636.2', '71.0.3578.93', '73.0.3636.1',
                        '73.0.3636.0', '72.0.3626.12', '71.0.3578.92', '73.0.3635.1',
                        '73.0.3635.0', '72.0.3626.11', '71.0.3578.91', '73.0.3634.2',
                        '73.0.3634.1', '73.0.3634.0', '72.0.3626.10', '71.0.3578.90',
                        '71.0.3578.89', '73.0.3633.2', '73.0.3633.1', '73.0.3633.0',
                        '72.0.3610.4', '72.0.3626.9', '71.0.3578.88', '73.0.3632.5',
                        '73.0.3632.4', '73.0.3632.3', '73.0.3632.2', '73.0.3632.1',
                        '73.0.3632.0', '72.0.3626.8', '71.0.3578.87', '73.0.3631.2',
                        '73.0.3631.1', '73.0.3631.0', '72.0.3626.7', '71.0.3578.86',
                        '72.0.3626.6', '73.0.3630.1', '73.0.3630.0', '72.0.3626.5',
                        '71.0.3578.85', '72.0.3626.4', '73.0.3628.3', '73.0.3628.2',
                        '73.0.3629.1', '73.0.3629.0', '72.0.3626.3', '71.0.3578.84',
                        '73.0.3628.1', '73.0.3628.0', '71.0.3578.83', '73.0.3627.1',
                        '73.0.3627.0', '72.0.3626.2', '71.0.3578.82', '71.0.3578.81',
                        '71.0.3578.80', '72.0.3626.1', '72.0.3626.0', '71.0.3578.79',
                        '70.0.3538.124', '71.0.3578.78', '72.0.3623.4', '72.0.3625.2',
                        '72.0.3625.1', '72.0.3625.0', '71.0.3578.77', '70.0.3538.123',
                        '72.0.3624.4', '72.0.3624.3', '72.0.3624.2', '71.0.3578.76',
                        '72.0.3624.1', '72.0.3624.0', '72.0.3623.3', '71.0.3578.75',
                        '70.0.3538.122', '71.0.3578.74', '72.0.3623.2', '72.0.3610.3',
                        '72.0.3623.1', '72.0.3623.0', '72.0.3622.3', '72.0.3622.2',
                        '71.0.3578.73', '70.0.3538.121', '72.0.3622.1', '72.0.3622.0',
                        '71.0.3578.72', '70.0.3538.120', '72.0.3621.1', '72.0.3621.0',
                        '71.0.3578.71', '70.0.3538.119', '72.0.3620.1', '72.0.3620.0',
                        '71.0.3578.70', '70.0.3538.118', '71.0.3578.69', '72.0.3619.1',
                        '72.0.3619.0', '71.0.3578.68', '70.0.3538.117', '71.0.3578.67',
                        '72.0.3618.1', '72.0.3618.0', '71.0.3578.66', '70.0.3538.116',
                        '72.0.3617.1', '72.0.3617.0', '71.0.3578.65', '70.0.3538.115',
                        '72.0.3602.3', '71.0.3578.64', '72.0.3616.1', '72.0.3616.0',
                        '71.0.3578.63', '70.0.3538.114', '71.0.3578.62', '72.0.3615.1',
                        '72.0.3615.0', '71.0.3578.61', '70.0.3538.113', '72.0.3614.1',
                        '72.0.3614.0', '71.0.3578.60', '70.0.3538.112', '72.0.3613.1',
                        '72.0.3613.0', '71.0.3578.59', '70.0.3538.111', '72.0.3612.2',
                        '72.0.3612.1', '72.0.3612.0', '70.0.3538.110', '71.0.3578.58',
                        '70.0.3538.109', '72.0.3611.2', '72.0.3611.1', '72.0.3611.0',
                        '71.0.3578.57', '70.0.3538.108', '72.0.3610.2', '71.0.3578.56',
                        '71.0.3578.55', '72.0.3610.1', '72.0.3610.0', '71.0.3578.54',
                        '70.0.3538.107', '71.0.3578.53', '72.0.3609.3', '71.0.3578.52',
                        '72.0.3609.2', '71.0.3578.51', '72.0.3608.5', '72.0.3609.1',
                        '72.0.3609.0', '71.0.3578.50', '70.0.3538.106', '72.0.3608.4',
                        '72.0.3608.3', '72.0.3608.2', '71.0.3578.49', '72.0.3608.1',
                        '72.0.3608.0', '70.0.3538.105', '71.0.3578.48', '72.0.3607.1',
                        '72.0.3607.0', '71.0.3578.47', '70.0.3538.104', '72.0.3606.2',
                        '72.0.3606.1', '72.0.3606.0', '71.0.3578.46', '70.0.3538.103',
                        '70.0.3538.102', '72.0.3605.3', '72.0.3605.2', '72.0.3605.1',
                        '72.0.3605.0', '71.0.3578.45', '70.0.3538.101', '71.0.3578.44',
                        '71.0.3578.43', '70.0.3538.100', '70.0.3538.99', '71.0.3578.42',
                        '72.0.3604.1', '72.0.3604.0', '71.0.3578.41', '70.0.3538.98',
                        '71.0.3578.40', '72.0.3603.2', '72.0.3603.1', '72.0.3603.0',
                        '71.0.3578.39', '70.0.3538.97', '72.0.3602.2', '71.0.3578.38',
                        '71.0.3578.37', '72.0.3602.1', '72.0.3602.0', '71.0.3578.36',
                        '70.0.3538.96', '72.0.3601.1', '72.0.3601.0', '71.0.3578.35',
                        '70.0.3538.95', '72.0.3600.1', '72.0.3600.0', '71.0.3578.34',
                        '70.0.3538.94', '72.0.3599.3', '72.0.3599.2', '72.0.3599.1',
                        '72.0.3599.0', '71.0.3578.33', '70.0.3538.93', '72.0.3598.1',
                        '72.0.3598.0', '71.0.3578.32', '70.0.3538.87', '72.0.3597.1',
                        '72.0.3597.0', '72.0.3596.2', '71.0.3578.31', '70.0.3538.86',
                        '71.0.3578.30', '71.0.3578.29', '72.0.3596.1', '72.0.3596.0',
                        '71.0.3578.28', '70.0.3538.85', '72.0.3595.2', '72.0.3591.3',
                        '72.0.3595.1', '72.0.3595.0', '71.0.3578.27', '70.0.3538.84',
                        '72.0.3594.1', '72.0.3594.0', '71.0.3578.26', '70.0.3538.83',
                        '72.0.3593.2', '72.0.3593.1', '72.0.3593.0', '71.0.3578.25',
                        '70.0.3538.82', '72.0.3589.3', '72.0.3592.2', '72.0.3592.1',
                        '72.0.3592.0', '71.0.3578.24', '72.0.3589.2', '70.0.3538.81',
                        '70.0.3538.80', '72.0.3591.2', '72.0.3591.1', '72.0.3591.0',
                        '71.0.3578.23', '70.0.3538.79', '71.0.3578.22', '72.0.3590.1',
                        '72.0.3590.0', '71.0.3578.21', '70.0.3538.78', '70.0.3538.77',
                        '72.0.3589.1', '72.0.3589.0', '71.0.3578.20', '70.0.3538.76',
                        '71.0.3578.19', '70.0.3538.75', '72.0.3588.1', '72.0.3588.0',
                        '71.0.3578.18', '70.0.3538.74', '72.0.3586.2', '72.0.3587.0',
                        '71.0.3578.17', '70.0.3538.73', '72.0.3586.1', '72.0.3586.0',
                        '71.0.3578.16', '70.0.3538.72', '72.0.3585.1', '72.0.3585.0',
                        '71.0.3578.15', '70.0.3538.71', '71.0.3578.14', '72.0.3584.1',
                        '72.0.3584.0', '71.0.3578.13', '70.0.3538.70', '72.0.3583.2',
                        '71.0.3578.12', '72.0.3583.1', '72.0.3583.0', '71.0.3578.11',
                        '70.0.3538.69', '71.0.3578.10', '72.0.3582.0', '72.0.3581.4',
                        '71.0.3578.9', '70.0.3538.67', '72.0.3581.3', '72.0.3581.2',
                        '72.0.3581.1', '72.0.3581.0', '71.0.3578.8', '70.0.3538.66',
                        '72.0.3580.1', '72.0.3580.0', '71.0.3578.7', '70.0.3538.65',
                        '71.0.3578.6', '72.0.3579.1', '72.0.3579.0', '71.0.3578.5',
                        '70.0.3538.64', '71.0.3578.4', '71.0.3578.3', '71.0.3578.2',
                        '71.0.3578.1', '71.0.3578.0', '70.0.3538.63', '69.0.3497.128',
                        '70.0.3538.62', '70.0.3538.61', '70.0.3538.60', '70.0.3538.59',
                        '71.0.3577.1', '71.0.3577.0', '70.0.3538.58', '69.0.3497.127',
                        '71.0.3576.2', '71.0.3576.1', '71.0.3576.0', '70.0.3538.57',
                        '70.0.3538.56', '71.0.3575.2', '70.0.3538.55', '69.0.3497.126',
                        '70.0.3538.54', '71.0.3575.1', '71.0.3575.0', '71.0.3574.1',
                        '71.0.3574.0', '70.0.3538.53', '69.0.3497.125', '70.0.3538.52',
                        '71.0.3573.1', '71.0.3573.0', '70.0.3538.51', '69.0.3497.124',
                        '71.0.3572.1', '71.0.3572.0', '70.0.3538.50', '69.0.3497.123',
                        '71.0.3571.2', '70.0.3538.49', '69.0.3497.122', '71.0.3571.1',
                        '71.0.3571.0', '70.0.3538.48', '69.0.3497.121', '71.0.3570.1',
                        '71.0.3570.0', '70.0.3538.47', '69.0.3497.120', '71.0.3568.2',
                        '71.0.3569.1', '71.0.3569.0', '70.0.3538.46', '69.0.3497.119',
                        '70.0.3538.45', '71.0.3568.1', '71.0.3568.0', '70.0.3538.44',
                        '69.0.3497.118', '70.0.3538.43', '70.0.3538.42', '71.0.3567.1',
                        '71.0.3567.0', '70.0.3538.41', '69.0.3497.117', '71.0.3566.1',
                        '71.0.3566.0', '70.0.3538.40', '69.0.3497.116', '71.0.3565.1',
                        '71.0.3565.0', '70.0.3538.39', '69.0.3497.115', '71.0.3564.1',
                        '71.0.3564.0', '70.0.3538.38', '69.0.3497.114', '71.0.3563.0',
                        '71.0.3562.2', '70.0.3538.37', '69.0.3497.113', '70.0.3538.36',
                        '70.0.3538.35', '71.0.3562.1', '71.0.3562.0', '70.0.3538.34',
                        '69.0.3497.112', '70.0.3538.33', '71.0.3561.1', '71.0.3561.0',
                        '70.0.3538.32', '69.0.3497.111', '71.0.3559.6', '71.0.3560.1',
                        '71.0.3560.0', '71.0.3559.5', '71.0.3559.4', '70.0.3538.31',
                        '69.0.3497.110', '71.0.3559.3', '70.0.3538.30', '69.0.3497.109',
                        '71.0.3559.2', '71.0.3559.1', '71.0.3559.0', '70.0.3538.29',
                        '69.0.3497.108', '71.0.3558.2', '71.0.3558.1', '71.0.3558.0',
                        '70.0.3538.28', '69.0.3497.107', '71.0.3557.2', '71.0.3557.1',
                        '71.0.3557.0', '70.0.3538.27', '69.0.3497.106', '71.0.3554.4',
                        '70.0.3538.26', '71.0.3556.1', '71.0.3556.0', '70.0.3538.25',
                        '71.0.3554.3', '69.0.3497.105', '71.0.3554.2', '70.0.3538.24',
                        '69.0.3497.104', '71.0.3555.2', '70.0.3538.23', '71.0.3555.1',
                        '71.0.3555.0', '70.0.3538.22', '69.0.3497.103', '71.0.3554.1',
                        '71.0.3554.0', '70.0.3538.21', '69.0.3497.102', '71.0.3553.3',
                        '70.0.3538.20', '69.0.3497.101', '71.0.3553.2', '69.0.3497.100',
                        '71.0.3553.1', '71.0.3553.0', '70.0.3538.19', '69.0.3497.99',
                        '69.0.3497.98', '69.0.3497.97', '71.0.3552.6', '71.0.3552.5',
                        '71.0.3552.4', '71.0.3552.3', '71.0.3552.2', '71.0.3552.1',
                        '71.0.3552.0', '70.0.3538.18', '69.0.3497.96', '71.0.3551.3',
                        '71.0.3551.2', '71.0.3551.1', '71.0.3551.0', '70.0.3538.17',
                        '69.0.3497.95', '71.0.3550.3', '71.0.3550.2', '71.0.3550.1',
                        '71.0.3550.0', '70.0.3538.16', '69.0.3497.94', '71.0.3549.1',
                        '71.0.3549.0', '70.0.3538.15', '69.0.3497.93', '69.0.3497.92',
                        '71.0.3548.1', '71.0.3548.0', '70.0.3538.14', '69.0.3497.91',
                        '71.0.3547.1', '71.0.3547.0', '70.0.3538.13', '69.0.3497.90',
                        '71.0.3546.2', '69.0.3497.89', '71.0.3546.1', '71.0.3546.0',
                        '70.0.3538.12', '69.0.3497.88', '71.0.3545.4', '71.0.3545.3',
                        '71.0.3545.2', '71.0.3545.1', '71.0.3545.0', '70.0.3538.11',
                        '69.0.3497.87', '71.0.3544.5', '71.0.3544.4', '71.0.3544.3',
                        '71.0.3544.2', '71.0.3544.1', '71.0.3544.0', '69.0.3497.86',
                        '70.0.3538.10', '69.0.3497.85', '70.0.3538.9', '69.0.3497.84',
                        '71.0.3543.4', '70.0.3538.8', '71.0.3543.3', '71.0.3543.2',
                        '71.0.3543.1', '71.0.3543.0', '70.0.3538.7', '69.0.3497.83',
                        '71.0.3542.2', '71.0.3542.1', '71.0.3542.0', '70.0.3538.6',
                        '69.0.3497.82', '69.0.3497.81', '71.0.3541.1', '71.0.3541.0',
                        '70.0.3538.5', '69.0.3497.80', '71.0.3540.1', '71.0.3540.0',
                        '70.0.3538.4', '69.0.3497.79', '70.0.3538.3', '71.0.3539.1',
                        '71.0.3539.0', '69.0.3497.78', '68.0.3440.134', '69.0.3497.77',
                        '70.0.3538.2', '70.0.3538.1', '70.0.3538.0', '69.0.3497.76',
                        '68.0.3440.133', '69.0.3497.75', '70.0.3537.2', '70.0.3537.1',
                        '70.0.3537.0', '69.0.3497.74', '68.0.3440.132', '70.0.3536.0',
                        '70.0.3535.5', '70.0.3535.4', '70.0.3535.3', '69.0.3497.73',
                        '68.0.3440.131', '70.0.3532.8', '70.0.3532.7', '69.0.3497.72',
                        '69.0.3497.71', '70.0.3535.2', '70.0.3535.1', '70.0.3535.0',
                        '69.0.3497.70', '68.0.3440.130', '69.0.3497.69', '68.0.3440.129',
                        '70.0.3534.4', '70.0.3534.3', '70.0.3534.2', '70.0.3534.1',
                        '70.0.3534.0', '69.0.3497.68', '68.0.3440.128', '70.0.3533.2',
                        '70.0.3533.1', '70.0.3533.0', '69.0.3497.67', '68.0.3440.127',
                        '70.0.3532.6', '70.0.3532.5', '70.0.3532.4', '69.0.3497.66',
                        '68.0.3440.126', '70.0.3532.3', '70.0.3532.2', '70.0.3532.1',
                        '69.0.3497.60', '69.0.3497.65', '69.0.3497.64', '70.0.3532.0',
                        '70.0.3531.0', '70.0.3530.4', '70.0.3530.3', '70.0.3530.2',
                        '69.0.3497.58', '68.0.3440.125', '69.0.3497.57', '69.0.3497.56',
                        '69.0.3497.55', '69.0.3497.54', '70.0.3530.1', '70.0.3530.0',
                        '69.0.3497.53', '68.0.3440.124', '69.0.3497.52', '70.0.3529.3',
                        '70.0.3529.2', '70.0.3529.1', '70.0.3529.0', '69.0.3497.51',
                        '70.0.3528.4', '68.0.3440.123', '70.0.3528.3', '70.0.3528.2',
                        '70.0.3528.1', '70.0.3528.0', '69.0.3497.50', '68.0.3440.122',
                        '70.0.3527.1', '70.0.3527.0', '69.0.3497.49', '68.0.3440.121',
                        '70.0.3526.1', '70.0.3526.0', '68.0.3440.120', '69.0.3497.48',
                        '69.0.3497.47', '68.0.3440.119', '68.0.3440.118', '70.0.3525.5',
                        '70.0.3525.4', '70.0.3525.3', '68.0.3440.117', '69.0.3497.46',
                        '70.0.3525.2', '70.0.3525.1', '70.0.3525.0', '69.0.3497.45',
                        '68.0.3440.116', '70.0.3524.4', '70.0.3524.3', '69.0.3497.44',
                        '70.0.3524.2', '70.0.3524.1', '70.0.3524.0', '70.0.3523.2',
                        '69.0.3497.43', '68.0.3440.115', '70.0.3505.9', '69.0.3497.42',
                        '70.0.3505.8', '70.0.3523.1', '70.0.3523.0', '69.0.3497.41',
                        '68.0.3440.114', '70.0.3505.7', '69.0.3497.40', '70.0.3522.1',
                        '70.0.3522.0', '70.0.3521.2', '69.0.3497.39', '68.0.3440.113',
                        '70.0.3505.6', '70.0.3521.1', '70.0.3521.0', '69.0.3497.38',
                        '68.0.3440.112', '70.0.3520.1', '70.0.3520.0', '69.0.3497.37',
                        '68.0.3440.111', '70.0.3519.3', '70.0.3519.2', '70.0.3519.1',
                        '70.0.3519.0', '69.0.3497.36', '68.0.3440.110', '70.0.3518.1',
                        '70.0.3518.0', '69.0.3497.35', '69.0.3497.34', '68.0.3440.109',
                        '70.0.3517.1', '70.0.3517.0', '69.0.3497.33', '68.0.3440.108',
                        '69.0.3497.32', '70.0.3516.3', '70.0.3516.2', '70.0.3516.1',
                        '70.0.3516.0', '69.0.3497.31', '68.0.3440.107', '70.0.3515.4',
                        '68.0.3440.106', '70.0.3515.3', '70.0.3515.2', '70.0.3515.1',
                        '70.0.3515.0', '69.0.3497.30', '68.0.3440.105', '68.0.3440.104',
                        '70.0.3514.2', '70.0.3514.1', '70.0.3514.0', '69.0.3497.29',
                        '68.0.3440.103', '70.0.3513.1', '70.0.3513.0', '69.0.3497.28')
    return _USER_AGENT_TPL % random.choice(_CHROME_VERSIONS)


std_headers = {'User-Agent':random_user_agent(), 
 'Accept-Charset':'ISO-8859-1,utf-8;q=0.7,*;q=0.7', 
 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 
 'Accept-Encoding':'gzip, deflate', 
 'Accept-Language':'en-us,en;q=0.5'}
USER_AGENTS = {'Safari': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27'}
NO_DEFAULT = object()
ENGLISH_MONTH_NAMES = [
 'January', 'February', 'March', 'April', 'May', 'June',
 'July', 'August', 'September', 'October', 'November', 'December']
MONTH_NAMES = {'en':ENGLISH_MONTH_NAMES, 
 'fr':[
  'janvier', 'février', 'mars', 'avril', 'mai', 'juin',
  'juillet', 'août', 'septembre', 'octobre', 'novembre', 'décembre']}
KNOWN_EXTENSIONS = ('mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v', 'aac', 'flv', 'f4v',
                    'f4a', 'f4b', 'webm', 'ogg', 'ogv', 'oga', 'ogx', 'spx', 'opus',
                    'mkv', 'mka', 'mk3d', 'avi', 'divx', 'mov', 'asf', 'wmv', 'wma',
                    '3gp', '3g2', 'mp3', 'flac', 'ape', 'wav', 'f4f', 'f4m', 'm3u8',
                    'smil')
ACCENT_CHARS = dict(zip('ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖŐØŒÙÚÛÜŰÝÞßàáâãäåæçèéêëìíîïðñòóôõöőøœùúûüűýþÿ', itertools.chain('AAAAAA', ['AE'], 'CEEEEIIIIDNOOOOOOO', ['OE'], 'UUUUUY', ['TH', 'ss'], 'aaaaaa', ['ae'], 'ceeeeiiiionooooooo', ['oe'], 'uuuuuy', ['th'], 'y')))
DATE_FORMATS = ('%d %B %Y', '%d %b %Y', '%B %d %Y', '%B %dst %Y', '%B %dnd %Y', '%B %drd %Y',
                '%B %dth %Y', '%b %d %Y', '%b %dst %Y', '%b %dnd %Y', '%b %drd %Y',
                '%b %dth %Y', '%b %dst %Y %I:%M', '%b %dnd %Y %I:%M', '%b %drd %Y %I:%M',
                '%b %dth %Y %I:%M', '%Y %m %d', '%Y-%m-%d', '%Y/%m/%d', '%Y/%m/%d %H:%M',
                '%Y/%m/%d %H:%M:%S', '%Y-%m-%d %H:%M', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f',
                '%d.%m.%Y %H:%M', '%d.%m.%Y %H.%M', '%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%dT%H:%M:%S.%fZ',
                '%Y-%m-%dT%H:%M:%S.%f0Z', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S.%f',
                '%Y-%m-%dT%H:%M', '%b %d %Y at %H:%M', '%b %d %Y at %H:%M:%S', '%B %d %Y at %H:%M',
                '%B %d %Y at %H:%M:%S')
DATE_FORMATS_DAY_FIRST = list(DATE_FORMATS)
DATE_FORMATS_DAY_FIRST.extend([
 '%d-%m-%Y',
 '%d.%m.%Y',
 '%d.%m.%y',
 '%d/%m/%Y',
 '%d/%m/%y',
 '%d/%m/%Y %H:%M:%S'])
DATE_FORMATS_MONTH_FIRST = list(DATE_FORMATS)
DATE_FORMATS_MONTH_FIRST.extend([
 '%m-%d-%Y',
 '%m.%d.%Y',
 '%m/%d/%Y',
 '%m/%d/%y',
 '%m/%d/%Y %H:%M:%S'])
PACKED_CODES_RE = "}\\('(.+)',(\\d+),(\\d+),'([^']+)'\\.split\\('\\|'\\)"
JSON_LD_RE = '(?is)<script[^>]+type=(["\\\']?)application/ld\\+json\\1[^>]*>(?P<json_ld>.+?)</script>'

def preferredencoding():
    """Get preferred encoding.

    Returns the best encoding scheme for the system, based on
    locale.getpreferredencoding() and some further tweaks.
    """
    try:
        pref = locale.getpreferredencoding()
        'TEST'.encode(pref)
    except Exception:
        pref = 'UTF-8'

    return pref


def write_json_file(obj, fn):
    """ Encode obj as JSON and write it to fn, atomically if possible """
    fn = encodeFilename(fn)
    if sys.version_info < (3, 0) and sys.platform != 'win32':
        encoding = get_filesystem_encoding()
        path_basename = lambda f: os.path.basename(fn).decode(encoding)
        path_dirname = lambda f: os.path.dirname(fn).decode(encoding)
    else:
        path_basename = os.path.basename
        path_dirname = os.path.dirname
    args = {'suffix':'.tmp', 
     'prefix':path_basename(fn) + '.', 
     'dir':path_dirname(fn), 
     'delete':False}
    if sys.version_info < (3, 0):
        args['mode'] = 'wb'
    else:
        args.update({'mode':'w', 
         'encoding':'utf-8'})
    tf = (tempfile.NamedTemporaryFile)(**compat_kwargs(args))
    try:
        with tf:
            json.dump(obj, tf)
        if sys.platform == 'win32':
            try:
                os.unlink(fn)
            except OSError:
                pass

        try:
            mask = os.umask(0)
            os.umask(mask)
            os.chmod(tf.name, 438 & ~mask)
        except OSError:
            pass

        os.rename(tf.name, fn)
    except Exception:
        try:
            os.remove(tf.name)
        except OSError:
            pass

        raise


if sys.version_info >= (2, 7):

    def find_xpath_attr(node, xpath, key, val=None):
        """ Find the xpath xpath[@key=val] """
        assert re.match('^[a-zA-Z_-]+$', key)
        expr = xpath + ('[@%s]' % key if val is None else "[@%s='%s']" % (key, val))
        return node.find(expr)


else:

    def find_xpath_attr(node, xpath, key, val=None):
        for f in node.findall(compat_xpath(xpath)):
            if key not in f.attrib:
                continue
            if val is None or f.attrib.get(key) == val:
                return f


def xpath_with_ns(path, ns_map):
    components = [c.split(':') for c in path.split('/')]
    replaced = []
    for c in components:
        if len(c) == 1:
            replaced.append(c[0])
        else:
            ns, tag = c
            replaced.append('{%s}%s' % (ns_map[ns], tag))

    return '/'.join(replaced)


def xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT):

    def _find_xpath(xpath):
        return node.find(compat_xpath(xpath))

    if isinstance(xpath, (str, compat_str)):
        n = _find_xpath(xpath)
    else:
        for xp in xpath:
            n = _find_xpath(xp)
            if n is not None:
                break

    if n is None:
        if default is not NO_DEFAULT:
            return default
        if fatal:
            name = xpath if name is None else name
            raise ExtractorError('Could not find XML element %s' % name)
        else:
            return
    return n


def xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT):
    n = xpath_element(node, xpath, name, fatal=fatal, default=default)
    if n is None or (n == default):
        return n
    if n.text is None:
        if default is not NO_DEFAULT:
            return default
        if fatal:
            name = xpath if name is None else name
            raise ExtractorError("Could not find XML element's text %s" % name)
        else:
            return
    return n.text


def xpath_attr(node, xpath, key, name=None, fatal=False, default=NO_DEFAULT):
    n = find_xpath_attr(node, xpath, key)
    if n is None:
        if default is not NO_DEFAULT:
            return default
        if fatal:
            name = '%s[@%s]' % (xpath, key) if name is None else name
            raise ExtractorError('Could not find XML attribute %s' % name)
        else:
            return
    return n.attrib[key]


def get_element_by_id(id, html):
    """Return the content of the tag with the specified ID in the passed HTML document"""
    return get_element_by_attribute('id', id, html)


def get_element_by_class(class_name, html):
    """Return the content of the first tag with the specified class in the passed HTML document"""
    retval = get_elements_by_class(class_name, html)
    if retval:
        return retval[0]


def get_element_by_attribute(attribute, value, html, escape_value=True):
    retval = get_elements_by_attribute(attribute, value, html, escape_value)
    if retval:
        return retval[0]


def get_elements_by_class(class_name, html):
    """Return the content of all tags with the specified class in the passed HTML document as a list"""
    return get_elements_by_attribute('class',
      ('[^\\\'"]*\\b%s\\b[^\\\'"]*' % re.escape(class_name)), html,
      escape_value=False)


def get_elements_by_attribute(attribute, value, html, escape_value=True):
    """Return the content of the tag with the specified attribute in the passed HTML document"""
    value = re.escape(value) if escape_value else value
    retlist = []
    for m in re.finditer('(?xs)\n        <([a-zA-Z0-9:._-]+)\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|=\'[^\']*\'|))*?\n         \\s+%s=[\'"]?%s[\'"]?\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|=\'[^\']*\'|))*?\n        \\s*>\n        (?P<content>.*?)\n        </\\1>\n    ' % (re.escape(attribute), value), html):
        res = m.group('content')
        if res.startswith('"') or res.startswith("'"):
            res = res[1:-1]
        else:
            retlist.append(unescapeHTML(res))

    return retlist


class HTMLAttributeParser(compat_HTMLParser):
    __doc__ = 'Trivial HTML parser to gather the attributes for a single element'

    def __init__(self):
        self.attrs = {}
        compat_HTMLParser.__init__(self)

    def handle_starttag(self, tag, attrs):
        self.attrs = dict(attrs)


def extract_attributes(html_element):
    """Given a string for an HTML element such as
    <el
         a="foo" B="bar" c="&98;az" d=boz
         empty= noval entity="&amp;"
         sq='"' dq="'"
    >
    Decode and return a dictionary of attributes.
    {
        'a': 'foo', 'b': 'bar', c: 'baz', d: 'boz',
        'empty': '', 'noval': None, 'entity': '&',
        'sq': '"', 'dq': '''
    }.
    NB HTMLParser is stricter in Python 2.6 & 3.2 than in later versions,
    but the cases in the unit test will work for all of 2.6, 2.7, 3.2-3.5.
    """
    parser = HTMLAttributeParser()
    try:
        parser.feed(html_element)
        parser.close()
    except compat_HTMLParseError:
        pass

    return parser.attrs


def clean_html(html):
    """Clean an HTML snippet into a readable string"""
    if html is None:
        return html
    html = html.replace('\n', ' ')
    html = re.sub('(?u)\\s*<\\s*br\\s*/?\\s*>\\s*', '\n', html)
    html = re.sub('(?u)<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\n', html)
    html = re.sub('<.*?>', '', html)
    html = unescapeHTML(html)
    return html.strip()


def sanitize_open(filename, open_mode):
    """Try to open the given filename, and slightly tweak it if this fails.

    Attempts to open the given filename. If this fails, it tries to change
    the filename slightly, step by step, until it's either able to open it
    or it fails and raises a final exception, like the standard open()
    function.

    It returns the tuple (stream, definitive_file_name).
    """
    try:
        if filename == '-':
            if sys.platform == 'win32':
                import msvcrt
                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)
        stream = open(encodeFilename(filename), open_mode)
        return (
         stream, filename)
    except (IOError, OSError) as err:
        try:
            if err.errno in (errno.EACCES,):
                raise
            alt_filename = sanitize_path(filename)
            if alt_filename == filename:
                raise
            else:
                stream = open(encodeFilename(alt_filename), open_mode)
                return (
                 stream, alt_filename)
        finally:
            err = None
            del err


def timeconvert(timestr):
    """Convert RFC 2822 defined time string into system timestamp"""
    timestamp = None
    timetuple = email.utils.parsedate_tz(timestr)
    if timetuple is not None:
        timestamp = email.utils.mktime_tz(timetuple)
    return timestamp


def sanitize_filename(s, restricted=False, is_id=False):
    """Sanitizes a string so it could be used as part of a filename.
    If restricted is set, use a stricter subset of allowed characters.
    Set is_id if this is not an arbitrary string, but an ID that should be kept
    if possible.
    """

    def replace_insane(char):
        if restricted:
            if char in ACCENT_CHARS:
                return ACCENT_CHARS[char]
        if char == '?' or (ord(char) < 32 or ord(char) == 127):
            return ''
        if char == '"':
            if restricted:
                return ''
            return "'"
        if char == ':':
            if restricted:
                return '_-'
            return ' -'
        if char in '\\/|*<>':
            return '_'
        if restricted:
            if char in "!&'()[]{}$;`^,#" or (char.isspace()):
                return '_'
            if restricted:
                if ord(char) > 127:
                    return '_'
            return char

    s = re.sub('[0-9]+(?::[0-9]+)+', lambda m: m.group(0).replace(':', '_'), s)
    result = ''.join(map(replace_insane, s))
    if not is_id:
        while '__' in result:
            result = result.replace('__', '_')

        result = result.strip('_')
        if restricted:
            if result.startswith('-_'):
                result = result[2:]
        if result.startswith('-'):
            result = '_' + result[len('-'):]
        result = result.lstrip('.')
        if not result:
            result = '_'
        return result


def sanitize_path(s):
    """Sanitizes and normalizes path on Windows"""
    if sys.platform != 'win32':
        return s
    drive_or_unc, _ = os.path.splitdrive(s)
    if sys.version_info < (2, 7):
        if not drive_or_unc:
            drive_or_unc, _ = os.path.splitunc(s)
        norm_path = os.path.normpath(remove_start(s, drive_or_unc)).split(os.path.sep)
        if drive_or_unc:
            norm_path.pop(0)
        sanitized_path = [path_part if path_part in ('.', '..') else re.sub('(?:[/<>:"\\|\\\\?\\*]|[\\s.]$)', '#', path_part) for path_part in norm_path]
        if drive_or_unc:
            sanitized_path.insert(0, drive_or_unc + os.path.sep)
        return (os.path.join)(*sanitized_path)


def sanitize_url(url):
    if url.startswith('//'):
        return 'http:%s' % url
    COMMON_TYPOS = (('^httpss://', 'https://'), ('^rmtp([es]?)://', 'rtmp\\1://'))
    for mistake, fixup in COMMON_TYPOS:
        if re.match(mistake, url):
            return re.sub(mistake, fixup, url)

    return url


def sanitized_Request(url, *args, **kwargs):
    return (compat_urllib_request.Request)(sanitize_url(url), *args, **kwargs)


def expand_path(s):
    """Expand shell variables and ~"""
    return os.path.expandvars(compat_expanduser(s))


def orderedSet(iterable):
    """ Remove all duplicates from the input iterable """
    res = []
    for el in iterable:
        if el not in res:
            res.append(el)

    return res


def _htmlentity_transform(entity_with_semicolon):
    """Transforms an HTML entity to a character."""
    entity = entity_with_semicolon[:-1]
    if entity in compat_html_entities.name2codepoint:
        return compat_chr(compat_html_entities.name2codepoint[entity])
    if entity_with_semicolon in compat_html_entities_html5:
        return compat_html_entities_html5[entity_with_semicolon]
    mobj = re.match('#(x[0-9a-fA-F]+|[0-9]+)', entity)
    if mobj is not None:
        numstr = mobj.group(1)
        if numstr.startswith('x'):
            base = 16
            numstr = '0%s' % numstr
        else:
            base = 10
        try:
            return compat_chr(int(numstr, base))
        except ValueError:
            pass

        return '&%s;' % entity


def unescapeHTML(s):
    if s is None:
        return
    assert type(s) == compat_str
    return re.sub('&([^&;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)


def get_subprocess_encoding():
    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:
        encoding = preferredencoding()
    else:
        encoding = sys.getfilesystemencoding()
    if encoding is None:
        encoding = 'utf-8'
    return encoding


def encodeFilename(s, for_subprocess=False):
    """
    @param s The name of the file
    """
    assert type(s) == compat_str
    if sys.version_info >= (3, 0):
        return s
    if not for_subprocess:
        if sys.platform == 'win32':
            if sys.getwindowsversion()[0] >= 5:
                return s
    if sys.platform.startswith('java'):
        return s
    return s.encode(get_subprocess_encoding(), 'ignore')


def decodeFilename(b, for_subprocess=False):
    if sys.version_info >= (3, 0):
        return b
    if not isinstance(b, bytes):
        return b
    return b.decode(get_subprocess_encoding(), 'ignore')


def encodeArgument(s):
    if not isinstance(s, compat_str):
        s = s.decode('ascii')
    return encodeFilename(s, True)


def decodeArgument(b):
    return decodeFilename(b, True)


def decodeOption(optval):
    if optval is None:
        return optval
    if isinstance(optval, bytes):
        optval = optval.decode(preferredencoding())
    assert isinstance(optval, compat_str)
    return optval


def formatSeconds(secs):
    if secs > 3600:
        return '%d:%02d:%02d' % (secs // 3600, secs % 3600 // 60, secs % 60)
    if secs > 60:
        return '%d:%02d' % (secs // 60, secs % 60)
    return '%d' % secs


def make_HTTPS_handler(params, **kwargs):
    opts_no_check_certificate = params.get('nocheckcertificate', False)
    if hasattr(ssl, 'create_default_context'):
        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)
        if opts_no_check_certificate:
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
        try:
            return YoutubeDLHTTPSHandler(params, context=context, **kwargs)
        except TypeError:
            pass

        if sys.version_info < (3, 2):
            return YoutubeDLHTTPSHandler(params, **kwargs)
        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
        context.verify_mode = ssl.CERT_NONE if opts_no_check_certificate else ssl.CERT_REQUIRED
        context.set_default_verify_paths()
        return YoutubeDLHTTPSHandler(params, context=context, **kwargs)


def bug_reports_message():
    if ytdl_is_updateable():
        update_cmd = 'type  youtube-dl -U  to update'
    else:
        update_cmd = 'see  https://yt-dl.org/update  on how to update'
    msg = '; please report this issue on https://yt-dl.org/bug .'
    msg += ' Make sure you are using the latest version; %s.' % update_cmd
    msg += ' Be sure to call youtube-dl with the --verbose flag and include its complete output.'
    return msg


class YoutubeDLError(Exception):
    __doc__ = 'Base exception for YoutubeDL errors.'


class ExtractorError(YoutubeDLError):
    __doc__ = 'Error during info extraction.'

    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):
        """ tb, if given, is the original traceback (so that it can be printed out).
        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.
        """
        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):
            expected = True
        if video_id is not None:
            msg = video_id + ': ' + msg
        if cause:
            msg += ' (caused by %r)' % cause
        if not expected:
            msg += bug_reports_message()
        super(ExtractorError, self).__init__(msg)
        self.traceback = tb
        self.exc_info = sys.exc_info()
        self.cause = cause
        self.video_id = video_id

    def format_traceback(self):
        if self.traceback is None:
            return
        return ''.join(traceback.format_tb(self.traceback))


class UnsupportedError(ExtractorError):

    def __init__(self, url):
        super(UnsupportedError, self).__init__(('Unsupported URL: %s' % url),
          expected=True)
        self.url = url


class RegexNotFoundError(ExtractorError):
    __doc__ = "Error when a regex didn't match"


class GeoRestrictedError(ExtractorError):
    __doc__ = 'Geographic restriction Error exception.\n\n    This exception may be thrown when a video is not available from your\n    geographic location due to geographic restrictions imposed by a website.\n    '

    def __init__(self, msg, countries=None):
        super(GeoRestrictedError, self).__init__(msg, expected=True)
        self.msg = msg
        self.countries = countries


class DownloadError(YoutubeDLError):
    __doc__ = 'Download Error exception.\n\n    This exception may be thrown by FileDownloader objects if they are not\n    configured to continue on errors. They will contain the appropriate\n    error message.\n    '

    def __init__(self, msg, exc_info=None):
        """ exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). """
        super(DownloadError, self).__init__(msg)
        self.exc_info = exc_info


class SameFileError(YoutubeDLError):
    __doc__ = 'Same File exception.\n\n    This exception will be thrown by FileDownloader objects if they detect\n    multiple files would have to be downloaded to the same file on disk.\n    '


class PostProcessingError(YoutubeDLError):
    __doc__ = "Post Processing exception.\n\n    This exception may be raised by PostProcessor's .run() method to\n    indicate an error in the postprocessing task.\n    "

    def __init__(self, msg):
        super(PostProcessingError, self).__init__(msg)
        self.msg = msg


class MaxDownloadsReached(YoutubeDLError):
    __doc__ = ' --max-downloads limit has been reached. '


class UnavailableVideoError(YoutubeDLError):
    __doc__ = 'Unavailable Format exception.\n\n    This exception will be thrown when a video is requested\n    in a format that is not available for that video.\n    '


class ContentTooShortError(YoutubeDLError):
    __doc__ = 'Content Too Short exception.\n\n    This exception may be raised by FileDownloader objects when a file they\n    download is too small for what the server announced first, indicating\n    the connection was probably interrupted.\n    '

    def __init__(self, downloaded, expected):
        super(ContentTooShortError, self).__init__('Downloaded {0} bytes, expected {1} bytes'.format(downloaded, expected))
        self.downloaded = downloaded
        self.expected = expected


class XAttrMetadataError(YoutubeDLError):

    def __init__(self, code=None, msg='Unknown error'):
        super(XAttrMetadataError, self).__init__(msg)
        self.code = code
        self.msg = msg
        if self.code in (errno.ENOSPC, errno.EDQUOT) or 'No space left' in self.msg or 'Disk quota exceeded' in self.msg:
            self.reason = 'NO_SPACE'
        elif self.code == errno.E2BIG or 'Argument list too long' in self.msg:
            self.reason = 'VALUE_TOO_LONG'
        else:
            self.reason = 'NOT_SUPPORTED'


class XAttrUnavailableError(YoutubeDLError):
    pass


def _create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs):
    if sys.version_info < (3, 0):
        kwargs['strict'] = True
    hc = http_class(*args, **compat_kwargs(kwargs))
    source_address = ydl_handler._params.get('source_address')
    if source_address is not None:

        def _create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, source_address=None):
            host, port = address
            err = None
            addrs = socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM)
            af = socket.AF_INET if '.' in source_address[0] else socket.AF_INET6
            ip_addrs = [addr for addr in addrs if addr[0] == af]
            if addrs:
                if not ip_addrs:
                    ip_version = 'v4' if af == socket.AF_INET else 'v6'
                    raise socket.error("No remote IP%s addresses available for connect, can't use '%s' as source address" % (
                     ip_version, source_address[0]))
                for res in ip_addrs:
                    af, socktype, proto, canonname, sa = res
                    sock = None
                    try:
                        sock = socket.socket(af, socktype, proto)
                        if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                            sock.settimeout(timeout)
                        sock.bind(source_address)
                        sock.connect(sa)
                        err = None
                        return sock
                    except socket.error as _:
                        try:
                            err = _
                            if sock is not None:
                                sock.close()
                        finally:
                            _ = None
                            del _

            if err is not None:
                raise err
            else:
                raise socket.error('getaddrinfo returns an empty list')

        if hasattr(hc, '_create_connection'):
            hc._create_connection = _create_connection
        sa = (
         source_address, 0)
        if hasattr(hc, 'source_address'):
            hc.source_address = sa
        else:

            def _hc_connect(self, *args, **kwargs):
                sock = _create_connection((
                 self.host, self.port), self.timeout, sa)
                if is_https:
                    self.sock = ssl.wrap_socket(sock,
                      (self.key_file), (self.cert_file), ssl_version=(ssl.PROTOCOL_TLSv1))
                else:
                    self.sock = sock

            hc.connect = functools.partial(_hc_connect, hc)
    return hc


def handle_youtubedl_headers(headers):
    filtered_headers = headers
    if 'Youtubedl-no-compression' in filtered_headers:
        filtered_headers = dict(((k, v) for k, v in filtered_headers.items() if k.lower() != 'accept-encoding'))
        del filtered_headers['Youtubedl-no-compression']
    return filtered_headers


class YoutubeDLHandler(compat_urllib_request.HTTPHandler):
    __doc__ = 'Handler for HTTP requests and responses.\n\n    This class, when installed with an OpenerDirector, automatically adds\n    the standard headers to every HTTP request and handles gzipped and\n    deflated responses from web servers. If compression is to be avoided in\n    a particular request, the original request in the program code only has\n    to include the HTTP header "Youtubedl-no-compression", which will be\n    removed before making the real request.\n\n    Part of this code was copied from:\n\n    http://techknack.net/python-urllib2-handlers/\n\n    Andrew Rowls, the author of that code, agreed to release it to the\n    public domain.\n    '

    def __init__(self, params, *args, **kwargs):
        (compat_urllib_request.HTTPHandler.__init__)(self, *args, **kwargs)
        self._params = params

    def http_open(self, req):
        conn_class = compat_http_client.HTTPConnection
        socks_proxy = req.headers.get('Ytdl-socks-proxy')
        if socks_proxy:
            conn_class = make_socks_conn_class(conn_class, socks_proxy)
            del req.headers['Ytdl-socks-proxy']
        return self.do_open(functools.partial(_create_http_connection, self, conn_class, False), req)

    @staticmethod
    def deflate(data):
        try:
            return zlib.decompress(data, -zlib.MAX_WBITS)
        except zlib.error:
            return zlib.decompress(data)

    def http_request(self, req):
        url = req.get_full_url()
        url_escaped = escape_url(url)
        if url != url_escaped:
            req = update_Request(req, url=url_escaped)
        for h, v in std_headers.items():
            if h.capitalize() not in req.headers:
                req.add_header(h, v)

        req.headers = handle_youtubedl_headers(req.headers)
        if sys.version_info < (2, 7):
            if '#' in req.get_full_url():
                req._Request__original = req._Request__original.partition('#')[0]
                req._Request__r_type = req._Request__r_type.partition('#')[0]
        return req

    def http_response(self, req, resp):
        old_resp = resp
        if resp.headers.get('Content-encoding', '') == 'gzip':
            content = resp.read()
            gz = gzip.GzipFile(fileobj=(io.BytesIO(content)), mode='rb')
            try:
                uncompressed = io.BytesIO(gz.read())
            except IOError as original_ioerror:
                try:
                    for i in range(1, 1024):
                        try:
                            gz = gzip.GzipFile(fileobj=(io.BytesIO(content[:-i])), mode='rb')
                            uncompressed = io.BytesIO(gz.read())
                        except IOError:
                            continue

                        break
                    else:
                        raise original_ioerror
                finally:
                    original_ioerror = None
                    del original_ioerror

            resp = compat_urllib_request.addinfourl(uncompressed, old_resp.headers, old_resp.url, old_resp.code)
            resp.msg = old_resp.msg
            del resp.headers['Content-encoding']
        if resp.headers.get('Content-encoding', '') == 'deflate':
            gz = io.BytesIO(self.deflate(resp.read()))
            resp = compat_urllib_request.addinfourl(gz, old_resp.headers, old_resp.url, old_resp.code)
            resp.msg = old_resp.msg
            del resp.headers['Content-encoding']
        if 300 <= resp.code < 400:
            location = resp.headers.get('Location')
            if location:
                if sys.version_info >= (3, 0):
                    location = location.encode('iso-8859-1').decode('utf-8')
                else:
                    location = location.decode('utf-8')
                location_escaped = escape_url(location)
                if location != location_escaped:
                    del resp.headers['Location']
                    if sys.version_info < (3, 0):
                        location_escaped = location_escaped.encode('utf-8')
                    resp.headers['Location'] = location_escaped
        return resp

    https_request = http_request
    https_response = http_response


def make_socks_conn_class(base_class, socks_proxy):
    assert issubclass(base_class, (
     compat_http_client.HTTPConnection, compat_http_client.HTTPSConnection))
    url_components = compat_urlparse.urlparse(socks_proxy)
    if url_components.scheme.lower() == 'socks5':
        socks_type = ProxyType.SOCKS5
    elif url_components.scheme.lower() in ('socks', 'socks4'):
        socks_type = ProxyType.SOCKS4
    elif url_components.scheme.lower() == 'socks4a':
        socks_type = ProxyType.SOCKS4A

    def unquote_if_non_empty(s):
        if not s:
            return s
        return compat_urllib_parse_unquote_plus(s)

    proxy_args = (
     socks_type,
     url_components.hostname, url_components.port or 1080,
     True,
     unquote_if_non_empty(url_components.username),
     unquote_if_non_empty(url_components.password))

    class SocksConnection(base_class):

        def connect(self):
            self.sock = sockssocket()
            (self.sock.setproxy)(*proxy_args)
            if type(self.timeout) in (int, float):
                self.sock.settimeout(self.timeout)
            self.sock.connect((self.host, self.port))
            if isinstance(self, compat_http_client.HTTPSConnection):
                if hasattr(self, '_context'):
                    self.sock = self._context.wrap_socket((self.sock),
                      server_hostname=(self.host))
                else:
                    self.sock = ssl.wrap_socket(self.sock)

    return SocksConnection


class YoutubeDLHTTPSHandler(compat_urllib_request.HTTPSHandler):

    def __init__(self, params, https_conn_class=None, *args, **kwargs):
        (compat_urllib_request.HTTPSHandler.__init__)(self, *args, **kwargs)
        self._https_conn_class = https_conn_class or compat_http_client.HTTPSConnection
        self._params = params

    def https_open(self, req):
        kwargs = {}
        conn_class = self._https_conn_class
        if hasattr(self, '_context'):
            kwargs['context'] = self._context
        if hasattr(self, '_check_hostname'):
            kwargs['check_hostname'] = self._check_hostname
        socks_proxy = req.headers.get('Ytdl-socks-proxy')
        if socks_proxy:
            conn_class = make_socks_conn_class(conn_class, socks_proxy)
            del req.headers['Ytdl-socks-proxy']
        return (self.do_open)(
         (functools.partial(_create_http_connection, self, conn_class, True)), 
         req, **kwargs)


class YoutubeDLCookieJar(compat_cookiejar.MozillaCookieJar):
    __doc__ = '\n    See [1] for cookie file format.\n\n    1. https://curl.haxx.se/docs/http-cookies.html\n    '
    _HTTPONLY_PREFIX = '#HttpOnly_'
    _ENTRY_LEN = 7
    _HEADER = '# Netscape HTTP Cookie File\n# This file is generated by youtube-dl.  Do not edit.\n\n'
    _CookieFileEntry = collections.namedtuple('CookieFileEntry', ('domain_name', 'include_subdomains',
                                                                  'path', 'https_only',
                                                                  'expires_at', 'name',
                                                                  'value'))

    def save(self, filename=None, ignore_discard=False, ignore_expires=False):
        """
        Save cookies to a file.

        Most of the code is taken from CPython 3.8 and slightly adapted
        to support cookie files with UTF-8 in both python 2 and 3.
        """
        if filename is None:
            if self.filename is not None:
                filename = self.filename
            else:
                raise ValueError(compat_cookiejar.MISSING_FILENAME_TEXT)
        for cookie in self:
            if cookie.expires is None:
                cookie.expires = 0

        with io.open(filename, 'w', encoding='utf-8') as f:
            f.write(self._HEADER)
            now = time.time()
            for cookie in self:
                if not ignore_discard:
                    if cookie.discard:
                        continue
                if not ignore_expires:
                    if cookie.is_expired(now):
                        continue
                if cookie.secure:
                    secure = 'TRUE'
                else:
                    secure = 'FALSE'
                if cookie.domain.startswith('.'):
                    initial_dot = 'TRUE'
                else:
                    initial_dot = 'FALSE'
                if cookie.expires is not None:
                    expires = compat_str(cookie.expires)
                else:
                    expires = ''
                if cookie.value is None:
                    name = ''
                    value = cookie.name
                else:
                    name = cookie.name
                    value = cookie.value
                f.write('\t'.join([cookie.domain, initial_dot, cookie.path,
                 secure, expires, name, value]) + '\n')

    def load(self, filename=None, ignore_discard=False, ignore_expires=False):
        """Load cookies from a file."""
        if filename is None:
            if self.filename is not None:
                filename = self.filename
            else:
                raise ValueError(compat_cookiejar.MISSING_FILENAME_TEXT)

        def prepare_line(line):
            if line.startswith(self._HTTPONLY_PREFIX):
                line = line[len(self._HTTPONLY_PREFIX):]
            if not (line.startswith('#') or line.strip()):
                return line
            cookie_list = line.split('\t')
            if len(cookie_list) != self._ENTRY_LEN:
                raise compat_cookiejar.LoadError('invalid length %d' % len(cookie_list))
            cookie = (self._CookieFileEntry)(*cookie_list)
            if cookie.expires_at:
                if not cookie.expires_at.isdigit():
                    raise compat_cookiejar.LoadError('invalid expires at %s' % cookie.expires_at)
                return line

        cf = io.StringIO()
        with io.open(filename, encoding='utf-8') as f:
            for line in f:
                try:
                    cf.write(prepare_line(line))
                except compat_cookiejar.LoadError as e:
                    try:
                        write_string('WARNING: skipping cookie file entry due to %s: %r\n' % (
                         e, line), sys.stderr)
                        continue
                    finally:
                        e = None
                        del e

        cf.seek(0)
        self._really_load(cf, filename, ignore_discard, ignore_expires)
        for cookie in self:
            if cookie.expires == 0:
                cookie.expires = None
                cookie.discard = True


class YoutubeDLCookieProcessor(compat_urllib_request.HTTPCookieProcessor):

    def __init__(self, cookiejar=None):
        compat_urllib_request.HTTPCookieProcessor.__init__(self, cookiejar)

    def http_response(self, request, response):
        return compat_urllib_request.HTTPCookieProcessor.http_response(self, request, response)

    https_request = compat_urllib_request.HTTPCookieProcessor.http_request
    https_response = http_response


class YoutubeDLRedirectHandler(compat_urllib_request.HTTPRedirectHandler):
    if sys.version_info[0] < 3:

        def redirect_request(self, req, fp, code, msg, headers, newurl):
            return compat_urllib_request.HTTPRedirectHandler.redirect_request(self, req, fp, code, msg, headers, compat_str(newurl))


def extract_timezone(date_str):
    m = re.search('^.{8,}?(?P<tz>Z$| ?(?P<sign>\\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)', date_str)
    if not m:
        timezone = datetime.timedelta()
    else:
        date_str = date_str[:-len(m.group('tz'))]
        if not m.group('sign'):
            timezone = datetime.timedelta()
        else:
            sign = 1 if m.group('sign') == '+' else -1
            timezone = datetime.timedelta(hours=(sign * int(m.group('hours'))),
              minutes=(sign * int(m.group('minutes'))))
    return (
     timezone, date_str)


def parse_iso8601(date_str, delimiter='T', timezone=None):
    """ Return a UNIX timestamp from the given date """
    if date_str is None:
        return
    date_str = re.sub('\\.[0-9]+', '', date_str)
    if timezone is None:
        timezone, date_str = extract_timezone(date_str)
    try:
        date_format = '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)
        dt = datetime.datetime.strptime(date_str, date_format) - timezone
        return calendar.timegm(dt.timetuple())
    except ValueError:
        pass


def date_formats(day_first=True):
    if day_first:
        return DATE_FORMATS_DAY_FIRST
    return DATE_FORMATS_MONTH_FIRST


def unified_strdate(date_str, day_first=True):
    """Return a string with the date in the format YYYYMMDD"""
    if date_str is None:
        return
    upload_date = None
    date_str = date_str.replace(',', ' ')
    date_str = re.sub('(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)
    _, date_str = extract_timezone(date_str)
    for expression in date_formats(day_first):
        try:
            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')
        except ValueError:
            pass

    if upload_date is None:
        timetuple = email.utils.parsedate_tz(date_str)
        if timetuple:
            try:
                upload_date = (datetime.datetime)(*timetuple[:6]).strftime('%Y%m%d')
            except ValueError:
                pass

    if upload_date is not None:
        return compat_str(upload_date)


def unified_timestamp(date_str, day_first=True):
    if date_str is None:
        return
    date_str = re.sub('[,|]', '', date_str)
    pm_delta = 12 if re.search('(?i)PM', date_str) else 0
    timezone, date_str = extract_timezone(date_str)
    date_str = re.sub('(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)
    m = re.search('\\d{1,2}:\\d{1,2}(?:\\.\\d+)?(?P<tz>\\s*[A-Z]+)$', date_str)
    if m:
        date_str = date_str[:-len(m.group('tz'))]
    m = re.search('^([0-9]{4,}-[0-9]{1,2}-[0-9]{1,2}T[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{6})[0-9]+$', date_str)
    if m:
        date_str = m.group(1)
    for expression in date_formats(day_first):
        try:
            dt = datetime.datetime.strptime(date_str, expression) - timezone + datetime.timedelta(hours=pm_delta)
            return calendar.timegm(dt.timetuple())
        except ValueError:
            pass

    timetuple = email.utils.parsedate_tz(date_str)
    if timetuple:
        return calendar.timegm(timetuple) + pm_delta * 3600


def determine_ext(url, default_ext='unknown_video'):
    if url is None or ('.' not in url):
        return default_ext
    guess = url.partition('?')[0].rpartition('.')[2]
    if re.match('^[A-Za-z0-9]+$', guess):
        return guess
    if guess.rstrip('/') in KNOWN_EXTENSIONS:
        return guess.rstrip('/')
    return default_ext


def subtitles_filename(filename, sub_lang, sub_format, expected_real_ext=None):
    return replace_extension(filename, sub_lang + '.' + sub_format, expected_real_ext)


def date_from_str(date_str):
    """
    Return a datetime object from a string in the format YYYYMMDD or
    (now|today)[+-][0-9](day|week|month|year)(s)?"""
    today = datetime.date.today()
    if date_str in ('now', 'today'):
        return today
    if date_str == 'yesterday':
        return today - datetime.timedelta(days=1)
    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)
    if match is not None:
        sign = match.group('sign')
        time = int(match.group('time'))
        if sign == '-':
            time = -time
        unit = match.group('unit')
        if unit == 'month':
            unit = 'day'
            time *= 30
        elif unit == 'year':
            unit = 'day'
            time *= 365
        unit += 's'
        delta = (datetime.timedelta)(**{unit: time})
        return today + delta
    return datetime.datetime.strptime(date_str, '%Y%m%d').date()


def hyphenate_date(date_str):
    """
    Convert a date in 'YYYYMMDD' format to 'YYYY-MM-DD' format"""
    match = re.match('^(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$', date_str)
    if match is not None:
        return '-'.join(match.groups())
    return date_str


class DateRange(object):
    __doc__ = 'Represents a time interval between two dates'

    def __init__(self, start=None, end=None):
        """start and end must be strings in the format accepted by date"""
        if start is not None:
            self.start = date_from_str(start)
        else:
            self.start = datetime.datetime.min.date()
        if end is not None:
            self.end = date_from_str(end)
        else:
            self.end = datetime.datetime.max.date()
        if self.start > self.end:
            raise ValueError('Date range: "%s" , the start date must be before the end date' % self)

    @classmethod
    def day(cls, day):
        """Returns a range that only contains the given day"""
        return cls(day, day)

    def __contains__(self, date):
        """Check if the date is in the range"""
        if not isinstance(date, datetime.date):
            date = date_from_str(date)
        return self.start <= date <= self.end

    def __str__(self):
        return '%s - %s' % (self.start.isoformat(), self.end.isoformat())


def platform_name():
    """ Returns the platform name as a compat_str """
    res = platform.platform()
    if isinstance(res, bytes):
        res = res.decode(preferredencoding())
    assert isinstance(res, compat_str)
    return res


def _windows_write_string(s, out):
    """ Returns True if the string was written using special methods,
    False if it has yet to be written out."""
    import ctypes, ctypes.wintypes
    WIN_OUTPUT_IDS = {1:-11, 
     2:-12}
    try:
        fileno = out.fileno()
    except AttributeError:
        return False
    except io.UnsupportedOperation:
        return False
    else:
        if fileno not in WIN_OUTPUT_IDS:
            return False
        GetStdHandle = compat_ctypes_WINFUNCTYPE(ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD)((
         'GetStdHandle', ctypes.windll.kernel32))
        h = GetStdHandle(WIN_OUTPUT_IDS[fileno])
        WriteConsoleW = compat_ctypes_WINFUNCTYPE(ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.wintypes.LPWSTR, ctypes.wintypes.DWORD, ctypes.POINTER(ctypes.wintypes.DWORD), ctypes.wintypes.LPVOID)(('WriteConsoleW', ctypes.windll.kernel32))
        written = ctypes.wintypes.DWORD(0)
        GetFileType = compat_ctypes_WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(('GetFileType', ctypes.windll.kernel32))
        FILE_TYPE_CHAR = 2
        FILE_TYPE_REMOTE = 32768
        GetConsoleMode = compat_ctypes_WINFUNCTYPE(ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.POINTER(ctypes.wintypes.DWORD))((
         'GetConsoleMode', ctypes.windll.kernel32))
        INVALID_HANDLE_VALUE = ctypes.wintypes.DWORD(-1).value

        def not_a_console(handle):
            if handle == INVALID_HANDLE_VALUE or (handle is None):
                return True
            return GetFileType(handle) & ~FILE_TYPE_REMOTE != FILE_TYPE_CHAR or GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0

        if not_a_console(h):
            return False

        def next_nonbmp_pos(s):
            try:
                return next((i for i, c in enumerate(s) if ord(c) > 65535))
            except StopIteration:
                return len(s)

        while s:
            count = min(next_nonbmp_pos(s), 1024)
            ret = WriteConsoleW(h, s, count if count else 2, ctypes.byref(written), None)
            if ret == 0:
                raise OSError('Failed to write string')
            if not count:
                if not written.value == 2:
                    raise AssertionError
                else:
                    s = s[1:]
            else:
                assert written.value > 0
                s = s[written.value:]

        return True


def write_string(s, out=None, encoding=None):
    if out is None:
        out = sys.stderr
    assert type(s) == compat_str
    if sys.platform == 'win32':
        if encoding is None:
            if hasattr(out, 'fileno'):
                if _windows_write_string(s, out):
                    return
    if 'b' in getattr(out, 'mode', '') or sys.version_info[0] < 3:
        byt = s.encode(encoding or preferredencoding(), 'ignore')
        out.write(byt)
    elif hasattr(out, 'buffer'):
        enc = encoding or getattr(out, 'encoding', None) or preferredencoding()
        byt = s.encode(enc, 'ignore')
        out.buffer.write(byt)
    else:
        out.write(s)
    out.flush()


def bytes_to_intlist(bs):
    if not bs:
        return []
    if isinstance(bs[0], int):
        return list(bs)
    return [ord(c) for c in bs]


def intlist_to_bytes(xs):
    if not xs:
        return ''
    return compat_struct_pack('%dB' % len(xs), *xs)


if sys.platform == 'win32':
    import ctypes.wintypes, msvcrt

    class OVERLAPPED(ctypes.Structure):
        _fields_ = [
         (
          'Internal', ctypes.wintypes.LPVOID),
         (
          'InternalHigh', ctypes.wintypes.LPVOID),
         (
          'Offset', ctypes.wintypes.DWORD),
         (
          'OffsetHigh', ctypes.wintypes.DWORD),
         (
          'hEvent', ctypes.wintypes.HANDLE)]


    kernel32 = ctypes.windll.kernel32
    LockFileEx = kernel32.LockFileEx
    LockFileEx.argtypes = [
     ctypes.wintypes.HANDLE,
     ctypes.wintypes.DWORD,
     ctypes.wintypes.DWORD,
     ctypes.wintypes.DWORD,
     ctypes.wintypes.DWORD,
     ctypes.POINTER(OVERLAPPED)]
    LockFileEx.restype = ctypes.wintypes.BOOL
    UnlockFileEx = kernel32.UnlockFileEx
    UnlockFileEx.argtypes = [
     ctypes.wintypes.HANDLE,
     ctypes.wintypes.DWORD,
     ctypes.wintypes.DWORD,
     ctypes.wintypes.DWORD,
     ctypes.POINTER(OVERLAPPED)]
    UnlockFileEx.restype = ctypes.wintypes.BOOL
    whole_low = 4294967295
    whole_high = 2147483647

    def _lock_file(f, exclusive):
        overlapped = OVERLAPPED()
        overlapped.Offset = 0
        overlapped.OffsetHigh = 0
        overlapped.hEvent = 0
        f._lock_file_overlapped_p = ctypes.pointer(overlapped)
        handle = msvcrt.get_osfhandle(f.fileno())
        if not LockFileEx(handle, 2 if exclusive else 0, 0, whole_low, whole_high, f._lock_file_overlapped_p):
            raise OSError('Locking file failed: %r' % ctypes.FormatError())


    def _unlock_file(f):
        assert f._lock_file_overlapped_p
        handle = msvcrt.get_osfhandle(f.fileno())
        if not UnlockFileEx(handle, 0, whole_low, whole_high, f._lock_file_overlapped_p):
            raise OSError('Unlocking file failed: %r' % ctypes.FormatError())


else:
    try:
        import fcntl

        def _lock_file(f, exclusive):
            fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)


        def _unlock_file(f):
            fcntl.flock(f, fcntl.LOCK_UN)


    except ImportError:
        UNSUPPORTED_MSG = 'file locking is not supported on this platform'

        def _lock_file(f, exclusive):
            raise IOError(UNSUPPORTED_MSG)


        def _unlock_file(f):
            raise IOError(UNSUPPORTED_MSG)


class locked_file(object):

    def __init__(self, filename, mode, encoding=None):
        assert mode in ('r', 'a', 'w')
        self.f = io.open(filename, mode, encoding=encoding)
        self.mode = mode

    def __enter__(self):
        exclusive = self.mode != 'r'
        try:
            _lock_file(self.f, exclusive)
        except IOError:
            self.f.close()
            raise

        return self

    def __exit__(self, etype, value, traceback):
        try:
            _unlock_file(self.f)
        finally:
            self.f.close()

    def __iter__(self):
        return iter(self.f)

    def write(self, *args):
        return (self.f.write)(*args)

    def read(self, *args):
        return (self.f.read)(*args)


def get_filesystem_encoding():
    encoding = sys.getfilesystemencoding()
    if encoding is not None:
        return encoding
    return 'utf-8'


def shell_quote(args):
    quoted_args = []
    encoding = get_filesystem_encoding()
    for a in args:
        if isinstance(a, bytes):
            a = a.decode(encoding)
        else:
            quoted_args.append(compat_shlex_quote(a))

    return ' '.join(quoted_args)


def smuggle_url(url, data):
    """ Pass additional data in a URL for internal use. """
    url, idata = unsmuggle_url(url, {})
    data.update(idata)
    sdata = compat_urllib_parse_urlencode({'__youtubedl_smuggle': json.dumps(data)})
    return url + '#' + sdata


def unsmuggle_url(smug_url, default=None):
    if '#__youtubedl_smuggle' not in smug_url:
        return (smug_url, default)
    url, _, sdata = smug_url.rpartition('#')
    jsond = compat_parse_qs(sdata)['__youtubedl_smuggle'][0]
    data = json.loads(jsond)
    return (
     url, data)


def format_bytes(bytes):
    if bytes is None:
        return 'N/A'
    if type(bytes) is str:
        bytes = float(bytes)
    if bytes == 0.0:
        exponent = 0
    else:
        exponent = int(math.log(bytes, 1024.0))
    suffix = [
     'B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'][exponent]
    converted = float(bytes) / float(1024 ** exponent)
    return '%.2f%s' % (converted, suffix)


def lookup_unit_table(unit_table, s):
    units_re = '|'.join((re.escape(u) for u in unit_table))
    m = re.match('(?P<num>[0-9]+(?:[,.][0-9]*)?)\\s*(?P<unit>%s)\\b' % units_re, s)
    if not m:
        return
    num_str = m.group('num').replace(',', '.')
    mult = unit_table[m.group('unit')]
    return int(float(num_str) * mult)


def parse_filesize(s):
    if s is None:
        return
    _UNIT_TABLE = {'B':1, 
     'b':1, 
     'bytes':1, 
     'KiB':1024, 
     'KB':1000, 
     'kB':1024, 
     'Kb':1000, 
     'kb':1000, 
     'kilobytes':1000, 
     'kibibytes':1024, 
     'MiB':1048576, 
     'MB':1000000, 
     'mB':1048576, 
     'Mb':1000000, 
     'mb':1000000, 
     'megabytes':1000000, 
     'mebibytes':1048576, 
     'GiB':1073741824, 
     'GB':1000000000, 
     'gB':1073741824, 
     'Gb':1000000000, 
     'gb':1000000000, 
     'gigabytes':1000000000, 
     'gibibytes':1073741824, 
     'TiB':1099511627776, 
     'TB':1000000000000, 
     'tB':1099511627776, 
     'Tb':1000000000000, 
     'tb':1000000000000, 
     'terabytes':1000000000000, 
     'tebibytes':1099511627776, 
     'PiB':1125899906842624, 
     'PB':1000000000000000, 
     'pB':1125899906842624, 
     'Pb':1000000000000000, 
     'pb':1000000000000000, 
     'petabytes':1000000000000000, 
     'pebibytes':1125899906842624, 
     'EiB':1152921504606846976, 
     'EB':1000000000000000000, 
     'eB':1152921504606846976, 
     'Eb':1000000000000000000, 
     'eb':1000000000000000000, 
     'exabytes':1000000000000000000, 
     'exbibytes':1152921504606846976, 
     'ZiB':1180591620717411303424, 
     'ZB':1000000000000000000000, 
     'zB':1180591620717411303424, 
     'Zb':1000000000000000000000, 
     'zb':1000000000000000000000, 
     'zettabytes':1000000000000000000000, 
     'zebibytes':1180591620717411303424, 
     'YiB':1208925819614629174706176, 
     'YB':1000000000000000000000000, 
     'yB':1208925819614629174706176, 
     'Yb':1000000000000000000000000, 
     'yb':1000000000000000000000000, 
     'yottabytes':1000000000000000000000000, 
     'yobibytes':1208925819614629174706176}
    return lookup_unit_table(_UNIT_TABLE, s)


def parse_count(s):
    if s is None:
        return
    s = s.strip()
    if re.match('^[\\d,.]+$', s):
        return str_to_int(s)
    _UNIT_TABLE = {'k':1000, 
     'K':1000, 
     'm':1000000, 
     'M':1000000, 
     'kk':1000000, 
     'KK':1000000}
    return lookup_unit_table(_UNIT_TABLE, s)


def parse_resolution(s):
    if s is None:
        return {}
    mobj = re.search('\\b(?P<w>\\d+)\\s*[xX×]\\s*(?P<h>\\d+)\\b', s)
    if mobj:
        return {'width':int(mobj.group('w')), 
         'height':int(mobj.group('h'))}
    mobj = re.search('\\b(\\d+)[pPiI]\\b', s)
    if mobj:
        return {'height': int(mobj.group(1))}
    mobj = re.search('\\b([48])[kK]\\b', s)
    if mobj:
        return {'height': int(mobj.group(1)) * 540}
    return {}


def parse_bitrate(s):
    if not isinstance(s, compat_str):
        return
    mobj = re.search('\\b(\\d+)\\s*kbps', s)
    if mobj:
        return int(mobj.group(1))


def month_by_name(name, lang='en'):
    """ Return the number of a month by (locale-independently) English name """
    month_names = MONTH_NAMES.get(lang, MONTH_NAMES['en'])
    try:
        return month_names.index(name) + 1
    except ValueError:
        return


def month_by_abbreviation(abbrev):
    """ Return the number of a month by (locale-independently) English
        abbreviations """
    try:
        return [s[:3] for s in ENGLISH_MONTH_NAMES].index(abbrev) + 1
    except ValueError:
        return


def fix_xml_ampersands(xml_str):
    """Replace all the '&' by '&amp;' in XML"""
    return re.sub('&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)', '&amp;', xml_str)


def setproctitle(title):
    assert isinstance(title, compat_str)
    if sys.platform.startswith('java'):
        return
    try:
        libc = ctypes.cdll.LoadLibrary('libc.so.6')
    except OSError:
        return
    except TypeError:
        return
    else:
        title_bytes = title.encode('utf-8')
        buf = ctypes.create_string_buffer(len(title_bytes))
        buf.value = title_bytes
        try:
            libc.prctl(15, buf, 0, 0, 0)
        except AttributeError:
            return


def remove_start(s, start):
    if s is not None:
        if s.startswith(start):
            return s[len(start):]
    return s


def remove_end(s, end):
    if s is not None:
        if s.endswith(end):
            return s[:-len(end)]
    return s


def remove_quotes(s):
    if s is None or (len(s) < 2):
        return s
    for quote in ('"', "'"):
        if s[0] == quote:
            if s[(-1)] == quote:
                return s[1:-1]

    return s


def url_basename(url):
    path = compat_urlparse.urlparse(url).path
    return path.strip('/').split('/')[(-1)]


def base_url(url):
    return re.match('https?://[^?#&]+/', url).group()


def urljoin(base, path):
    if isinstance(path, bytes):
        path = path.decode('utf-8')
    if not (isinstance(path, compat_str) and path):
        return
    if re.match('^(?:[a-zA-Z][a-zA-Z0-9+-.]*:)?//', path):
        return path
    if isinstance(base, bytes):
        base = base.decode('utf-8')
    if not (isinstance(base, compat_str) and re.match('^(?:https?:)?//', base)):
        return
    return compat_urlparse.urljoin(base, path)


class HEADRequest(compat_urllib_request.Request):

    def get_method(self):
        return 'HEAD'


class PUTRequest(compat_urllib_request.Request):

    def get_method(self):
        return 'PUT'


def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):
    if get_attr:
        if v is not None:
            v = getattr(v, get_attr, None)
    if v == '':
        v = None
    if v is None:
        return default
    try:
        return int(v) * invscale // scale
    except (ValueError, TypeError):
        return default


def str_or_none(v, default=None):
    if v is None:
        return default
    return compat_str(v)


def str_to_int(int_str):
    """ A more relaxed version of int_or_none """
    if isinstance(int_str, compat_integer_types):
        return int_str
    if isinstance(int_str, compat_str):
        int_str = re.sub('[,\\.\\+]', '', int_str)
        return int_or_none(int_str)


def float_or_none(v, scale=1, invscale=1, default=None):
    if v is None:
        return default
    try:
        return float(v) * invscale / scale
    except (ValueError, TypeError):
        return default


def bool_or_none(v, default=None):
    if isinstance(v, bool):
        return v
    return default


def strip_or_none(v, default=None):
    if isinstance(v, compat_str):
        return v.strip()
    return default


def url_or_none(url):
    if not (url and isinstance(url, compat_str)):
        return
    url = url.strip()
    if re.match('^(?:(?:https?|rt(?:m(?:pt?[es]?|fp)|sp[su]?)|mms|ftps?):)?//', url):
        return url


def parse_duration(s):
    if not isinstance(s, compat_basestring):
        return
    s = s.strip()
    days, hours, mins, secs, ms = [
     None] * 5
    m = re.match('(?:(?:(?:(?P<days>[0-9]+):)?(?P<hours>[0-9]+):)?(?P<mins>[0-9]+):)?(?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?Z?$', s)
    if m:
        days, hours, mins, secs, ms = m.groups()
    else:
        m = re.match('(?ix)(?:P?\n                (?:\n                    [0-9]+\\s*y(?:ears?)?\\s*\n                )?\n                (?:\n                    [0-9]+\\s*m(?:onths?)?\\s*\n                )?\n                (?:\n                    [0-9]+\\s*w(?:eeks?)?\\s*\n                )?\n                (?:\n                    (?P<days>[0-9]+)\\s*d(?:ays?)?\\s*\n                )?\n                T)?\n                (?:\n                    (?P<hours>[0-9]+)\\s*h(?:ours?)?\\s*\n                )?\n                (?:\n                    (?P<mins>[0-9]+)\\s*m(?:in(?:ute)?s?)?\\s*\n                )?\n                (?:\n                    (?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?\\s*s(?:ec(?:ond)?s?)?\\s*\n                )?Z?$', s)
        if m:
            days, hours, mins, secs, ms = m.groups()
        else:
            m = re.match('(?i)(?:(?P<hours>[0-9.]+)\\s*(?:hours?)|(?P<mins>[0-9.]+)\\s*(?:mins?\\.?|minutes?)\\s*)Z?$', s)
            if m:
                hours, mins = m.groups()
            else:
                return
    duration = 0
    if secs:
        duration += float(secs)
    if mins:
        duration += float(mins) * 60
    if hours:
        duration += float(hours) * 60 * 60
    if days:
        duration += float(days) * 24 * 60 * 60
    if ms:
        duration += float(ms)
    return duration


def prepend_extension(filename, ext, expected_real_ext=None):
    name, real_ext = os.path.splitext(filename)
    if not expected_real_ext or real_ext[1:] == expected_real_ext:
        return '{0}.{1}{2}'.format(name, ext, real_ext)
    return '{0}.{1}'.format(filename, ext)


def replace_extension--- This code section failed: ---

 L.3713         0  LOAD_GLOBAL              os
                2  LOAD_ATTR                path
                4  LOAD_METHOD              splitext
                6  LOAD_FAST                'filename'
                8  CALL_METHOD_1         1  '1 positional argument'
               10  UNPACK_SEQUENCE_2     2 
               12  STORE_FAST               'name'
               14  STORE_FAST               'real_ext'

 L.3714        16  LOAD_STR                 '{0}.{1}'
               18  LOAD_METHOD              format

 L.3715        20  LOAD_FAST                'expected_real_ext'
               22  POP_JUMP_IF_FALSE    40  'to 40'
               24  LOAD_FAST                'real_ext'
               26  LOAD_CONST               1
               28  LOAD_CONST               None
               30  BUILD_SLICE_2         2 
               32  BINARY_SUBSCR    
               34  LOAD_FAST                'expected_real_ext'
               36  COMPARE_OP               ==
               38  POP_JUMP_IF_FALSE    44  'to 44'
             40_0  COME_FROM            22  '22'
               40  LOAD_FAST                'name'
               42  JUMP_FORWARD         46  'to 46'
             44_0  COME_FROM            38  '38'
               44  LOAD_FAST                'filename'
             46_0  COME_FROM            42  '42'

 L.3716        46  LOAD_FAST                'ext'
               48  CALL_METHOD_2         2  '2 positional arguments'
               50  RETURN_VALUE     
               -1  RETURN_LAST      

Parse error at or near `COME_FROM' instruction at offset 44_0


def check_executable(exe, args=[]):
    """ Checks if the given binary is installed somewhere in PATH, and returns its name.
    args can be a list of arguments for a short output (like -version) """
    try:
        subprocess.Popen(([exe] + args), stdout=(subprocess.PIPE), stderr=(subprocess.PIPE)).communicate()
    except OSError:
        return False
    else:
        return exe


def get_exe_version(exe, args=[
 '--version'], version_re=None, unrecognized='present'):
    """ Returns the version of the specified executable,
    or False if the executable is not present """
    try:
        out, _ = subprocess.Popen(([
         encodeArgument(exe)] + args),
          stdin=(subprocess.PIPE),
          stdout=(subprocess.PIPE),
          stderr=(subprocess.STDOUT)).communicate()
    except OSError:
        return False
    else:
        if isinstance(out, bytes):
            out = out.decode('ascii', 'ignore')
        return detect_exe_version(out, version_re, unrecognized)


def detect_exe_version(output, version_re=None, unrecognized='present'):
    assert isinstance(output, compat_str)
    if version_re is None:
        version_re = 'version\\s+([-0-9._a-zA-Z]+)'
    m = re.search(version_re, output)
    if m:
        return m.group(1)
    return unrecognized


class PagedList(object):

    def __len__(self):
        return len(self.getslice())


class OnDemandPagedList(PagedList):

    def __init__(self, pagefunc, pagesize, use_cache=True):
        self._pagefunc = pagefunc
        self._pagesize = pagesize
        self._use_cache = use_cache
        if use_cache:
            self._cache = {}

    def getslice(self, start=0, end=None):
        res = []
        for pagenum in itertools.count(start // self._pagesize):
            firstid = pagenum * self._pagesize
            nextfirstid = pagenum * self._pagesize + self._pagesize
            if start >= nextfirstid:
                continue
            else:
                page_results = None
                if self._use_cache:
                    page_results = self._cache.get(pagenum)
                if page_results is None:
                    page_results = list(self._pagefunc(pagenum))
                if self._use_cache:
                    self._cache[pagenum] = page_results
                startv = start % self._pagesize if (firstid <= start < nextfirstid) else 0
            if end is not None:
                endv = (end - 1) % self._pagesize + 1 if (firstid <= end <= nextfirstid) else None
                if startv != 0 or (endv is not None):
                    page_results = page_results[startv:endv]
                res.extend(page_results)
                if len(page_results) + startv < self._pagesize:
                    break
                if end == nextfirstid:
                    break

        return res


class InAdvancePagedList(PagedList):

    def __init__(self, pagefunc, pagecount, pagesize):
        self._pagefunc = pagefunc
        self._pagecount = pagecount
        self._pagesize = pagesize

    def getslice(self, start=0, end=None):
        res = []
        start_page = start // self._pagesize
        end_page = self._pagecount if end is None else end // self._pagesize + 1
        skip_elems = start - start_page * self._pagesize
        only_more = None if end is None else end - start
        for pagenum in range(start_page, end_page):
            page = list(self._pagefunc(pagenum))
            if skip_elems:
                page = page[skip_elems:]
                skip_elems = None
            if only_more is not None:
                if len(page) < only_more:
                    only_more -= len(page)
                else:
                    page = page[:only_more]
                    res.extend(page)
                    break
            res.extend(page)

        return res


def uppercase_escape(s):
    unicode_escape = codecs.getdecoder('unicode_escape')
    return re.sub('\\\\U[0-9a-fA-F]{8}', lambda m: unicode_escape(m.group(0))[0], s)


def lowercase_escape(s):
    unicode_escape = codecs.getdecoder('unicode_escape')
    return re.sub('\\\\u[0-9a-fA-F]{4}', lambda m: unicode_escape(m.group(0))[0], s)


def escape_rfc3986(s):
    """Escape non-ASCII characters as suggested by RFC 3986"""
    if sys.version_info < (3, 0):
        if isinstance(s, compat_str):
            s = s.encode('utf-8')
    return compat_urllib_parse.quote(s, "%/;:@&=+$,!~*'()?#[]")


def escape_url(url):
    """Escape URL as suggested by RFC 3986"""
    url_parsed = compat_urllib_parse_urlparse(url)
    return url_parsed._replace(netloc=(url_parsed.netloc.encode('idna').decode('ascii')),
      path=(escape_rfc3986(url_parsed.path)),
      params=(escape_rfc3986(url_parsed.params)),
      query=(escape_rfc3986(url_parsed.query)),
      fragment=(escape_rfc3986(url_parsed.fragment))).geturl()


def read_batch_urls(batch_fd):

    def fixup(url):
        if not isinstance(url, compat_str):
            url = url.decode('utf-8', 'replace')
        BOM_UTF8 = 'ï»¿'
        if url.startswith(BOM_UTF8):
            url = url[len(BOM_UTF8):]
        url = url.strip()
        if url.startswith(('#', ';', ']')):
            return False
        return url

    with contextlib.closing(batch_fd) as fd:
        return [url for url in map(fixup, fd) if url]


def urlencode_postdata(*args, **kargs):
    return compat_urllib_parse_urlencode(*args, **kargs).encode('ascii')


def update_url_query(url, query):
    if not query:
        return url
    parsed_url = compat_urlparse.urlparse(url)
    qs = compat_parse_qs(parsed_url.query)
    qs.update(query)
    return compat_urlparse.urlunparse(parsed_url._replace(query=(compat_urllib_parse_urlencode(qs, True))))


def update_Request(req, url=None, data=None, headers={}, query={}):
    req_headers = req.headers.copy()
    req_headers.update(headers)
    req_data = data or req.data
    req_url = update_url_query(url or req.get_full_url(), query)
    req_get_method = req.get_method()
    if req_get_method == 'HEAD':
        req_type = HEADRequest
    elif req_get_method == 'PUT':
        req_type = PUTRequest
    else:
        req_type = compat_urllib_request.Request
    new_req = req_type(req_url,
      data=req_data, headers=req_headers, origin_req_host=(req.origin_req_host),
      unverifiable=(req.unverifiable))
    if hasattr(req, 'timeout'):
        new_req.timeout = req.timeout
    return new_req


def _multipart_encode_impl(data, boundary):
    content_type = 'multipart/form-data; boundary=%s' % boundary
    out = ''
    for k, v in data.items():
        out += '--' + boundary.encode('ascii') + '\r\n'
        if isinstance(k, compat_str):
            k = k.encode('utf-8')
        else:
            if isinstance(v, compat_str):
                v = v.encode('utf-8')
            content = 'Content-Disposition: form-data; name="' + k + '"\r\n\r\n' + v + '\r\n'
            if boundary.encode('ascii') in content:
                raise ValueError('Boundary overlaps with data')
            out += content

    out += '--' + boundary.encode('ascii') + '--\r\n'
    return (
     out, content_type)


def multipart_encode(data, boundary=None):
    """
    Encode a dict to RFC 7578-compliant form-data

    data:
        A dict where keys and values can be either Unicode or bytes-like
        objects.
    boundary:
        If specified a Unicode object, it's used as the boundary. Otherwise
        a random boundary is generated.

    Reference: https://tools.ietf.org/html/rfc7578
    """
    has_specified_boundary = boundary is not None
    while 1:
        if boundary is None:
            boundary = '---------------' + str(random.randrange(268435455, 4294967295))
        try:
            out, content_type = _multipart_encode_impl(data, boundary)
            break
        except ValueError:
            if has_specified_boundary:
                raise
            else:
                boundary = None

    return (
     out, content_type)


def dict_get(d, key_or_keys, default=None, skip_false_values=True):
    if isinstance(key_or_keys, (list, tuple)):
        for key in key_or_keys:
            if not key not in d:
                if not d[key] is None:
                    if skip_false_values:
                        if not d[key]:
                            continue
                        return d[key]

        return default
    return d.get(key_or_keys, default)


def try_get(src, getter, expected_type=None):
    if not isinstance(getter, (list, tuple)):
        getter = [
         getter]
    for get in getter:
        try:
            v = get(src)
        except (AttributeError, KeyError, TypeError, IndexError):
            pass
        else:
            if expected_type is None or isinstance(v, expected_type):
                return v


def merge_dicts--- This code section failed: ---

 L.4007         0  BUILD_MAP_0           0 
                2  STORE_FAST               'merged'

 L.4008         4  SETUP_LOOP          102  'to 102'
                6  LOAD_FAST                'dicts'
                8  GET_ITER         
             10_0  COME_FROM            98  '98'
               10  FOR_ITER            100  'to 100'
               12  STORE_FAST               'a_dict'

 L.4009        14  SETUP_LOOP           98  'to 98'
               16  LOAD_FAST                'a_dict'
               18  LOAD_METHOD              items
               20  CALL_METHOD_0         0  '0 positional arguments'
               22  GET_ITER         
             24_0  COME_FROM            94  '94'
             24_1  COME_FROM            84  '84'
             24_2  COME_FROM            76  '76'
             24_3  COME_FROM            62  '62'
             24_4  COME_FROM            58  '58'
             24_5  COME_FROM            40  '40'
               24  FOR_ITER             96  'to 96'
               26  UNPACK_SEQUENCE_2     2 
               28  STORE_FAST               'k'
               30  STORE_FAST               'v'

 L.4010        32  LOAD_FAST                'v'
               34  LOAD_CONST               None
               36  COMPARE_OP               is
               38  POP_JUMP_IF_FALSE    42  'to 42'

 L.4011        40  CONTINUE             24  'to 24'
             42_0  COME_FROM            38  '38'

 L.4012        42  LOAD_FAST                'k'
               44  LOAD_FAST                'merged'
               46  COMPARE_OP               not-in
               48  POP_JUMP_IF_TRUE     86  'to 86'

 L.4013        50  LOAD_GLOBAL              isinstance
               52  LOAD_FAST                'v'
               54  LOAD_GLOBAL              compat_str
               56  CALL_FUNCTION_2       2  '2 positional arguments'
               58  POP_JUMP_IF_FALSE_BACK    24  'to 24'
               60  LOAD_FAST                'v'
               62  POP_JUMP_IF_FALSE_BACK    24  'to 24'

 L.4014        64  LOAD_GLOBAL              isinstance
               66  LOAD_FAST                'merged'
               68  LOAD_FAST                'k'
               70  BINARY_SUBSCR    
               72  LOAD_GLOBAL              compat_str
               74  CALL_FUNCTION_2       2  '2 positional arguments'
               76  POP_JUMP_IF_FALSE_BACK    24  'to 24'

 L.4015        78  LOAD_FAST                'merged'
               80  LOAD_FAST                'k'
               82  BINARY_SUBSCR    
               84  POP_JUMP_IF_TRUE_BACK    24  'to 24'
             86_0  COME_FROM            48  '48'

 L.4016        86  LOAD_FAST                'v'
               88  LOAD_FAST                'merged'
               90  LOAD_FAST                'k'
               92  STORE_SUBSCR     
               94  JUMP_BACK            24  'to 24'
               96  POP_BLOCK        
             98_0  COME_FROM_LOOP       14  '14'
               98  JUMP_BACK            10  'to 10'
              100  POP_BLOCK        
            102_0  COME_FROM_LOOP        4  '4'

 L.4017       102  LOAD_FAST                'merged'
              104  RETURN_VALUE     
               -1  RETURN_LAST      

Parse error at or near `POP_BLOCK' instruction at offset 96


def encode_compat_str(string, encoding=preferredencoding(), errors='strict'):
    if isinstance(string, compat_str):
        return string
    return compat_str(string, encoding, errors)


US_RATINGS = {'G':0, 
 'PG':10, 
 'PG-13':13, 
 'R':16, 
 'NC':18}
TV_PARENTAL_GUIDELINES = {'TV-Y':0, 
 'TV-Y7':7, 
 'TV-G':0, 
 'TV-PG':0, 
 'TV-14':14, 
 'TV-MA':17}

def parse_age_limit(s):
    if type(s) == int:
        if 0 <= s <= 21:
            return s
        return
    if not isinstance(s, compat_basestring):
        return
    m = re.match('^(?P<age>\\d{1,2})\\+?$', s)
    if m:
        return int(m.group('age'))
    if s in US_RATINGS:
        return US_RATINGS[s]
    m = re.match('^TV[_-]?(%s)$' % '|'.join((k[3:] for k in TV_PARENTAL_GUIDELINES)), s)
    if m:
        return TV_PARENTAL_GUIDELINES[('TV-' + m.group(1))]


def strip_jsonp(code):
    return re.sub('(?sx)^\n            (?:window\\.)?(?P<func_name>[a-zA-Z0-9_.$]*)\n            (?:\\s*&&\\s*(?P=func_name))?\n            \\s*\\(\\s*(?P<callback_data>.*)\\);?\n            \\s*?(?://[^\\n]*)*$', '\\g<callback_data>', code)


def js_to_json(code):
    COMMENT_RE = '/\\*(?:(?!\\*/).)*?\\*/|//[^\\n]*'
    SKIP_RE = '\\s*(?:{comment})?\\s*'.format(comment=COMMENT_RE)
    INTEGER_TABLE = (
     (
      '(?s)^(0[xX][0-9a-fA-F]+){skip}:?$'.format(skip=SKIP_RE), 16),
     (
      '(?s)^(0+[0-7]+){skip}:?$'.format(skip=SKIP_RE), 8))

    def fix_kv(m):
        v = m.group(0)
        if v in ('true', 'false', 'null'):
            return v
        if not v.startswith('/*'):
            if v.startswith('//') or (v.startswith('!') or v == ','):
                return ''
            if v[0] in ("'", '"'):
                v = re.sub('(?s)\\\\.|"', lambda m: {'"':'\\"', 
                 "\\'":"'", 
                 '\\\n':'', 
                 '\\x':'\\u00'}.get(m.group(0), m.group(0)), v[1:-1])
            else:
                for regex, base in INTEGER_TABLE:
                    im = re.match(regex, v)
                    if im:
                        i = int(im.group(1), base)
                        if v.endswith(':'):
                            return '"%d":' % i
                        else:
                            return '%d' % i

            return '"%s"' % v

    return re.sub('(?sx)\n        "(?:[^"\\\\]*(?:\\\\\\\\|\\\\[\'"nurtbfx/\\n]))*[^"\\\\]*"|\n        \'(?:[^\'\\\\]*(?:\\\\\\\\|\\\\[\'"nurtbfx/\\n]))*[^\'\\\\]*\'|\n        {comment}|,(?={skip}[\\]}}])|\n        (?:(?<![0-9])[eE]|[a-df-zA-DF-Z_])[.a-zA-Z_0-9]*|\n        \\b(?:0[xX][0-9a-fA-F]+|0+[0-7]+)(?:{skip}:)?|\n        [0-9]+(?={skip}:)|\n        !+\n        '.format(comment=COMMENT_RE, skip=SKIP_RE), fix_kv, code)


def qualities(quality_ids):
    """ Get a numeric quality value out of a list of possible values """

    def q(qid):
        try:
            return quality_ids.index(qid)
        except ValueError:
            return -1

    return q


DEFAULT_OUTTMPL = '%(title)s-%(id)s.%(ext)s'

def limit_length(s, length):
    """ Add ellipses to overly long strings """
    if s is None:
        return
    ELLIPSES = '...'
    if len(s) > length:
        return s[:length - len(ELLIPSES)] + ELLIPSES
    return s


def version_tuple(v):
    return tuple((int(e) for e in re.split('[-.]', v)))


def is_outdated_version(version, limit, assume_new=True):
    if not version:
        return not assume_new
    try:
        return version_tuple(version) < version_tuple(limit)
    except ValueError:
        return not assume_new


def ytdl_is_updateable():
    """ Returns if youtube-dl can be updated with -U """
    from zipimport import zipimporter
    return isinstance(globals().get('__loader__'), zipimporter) or hasattr(sys, 'frozen')


def args_to_str(args):
    return ' '.join((compat_shlex_quote(a) for a in args))


def error_to_compat_str(err):
    err_str = str(err)
    if sys.version_info[0] < 3:
        err_str = err_str.decode(preferredencoding())
    return err_str


def mimetype2ext(mt):
    if mt is None:
        return
    ext = {'audio/mp4':'m4a', 
     'audio/mpeg':'mp3'}.get(mt)
    if ext is not None:
        return ext
    _, _, res = mt.rpartition('/')
    res = res.split(';')[0].strip().lower()
    return {'3gpp':'3gp', 
     'smptett+xml':'tt', 
     'ttaf+xml':'dfxp', 
     'ttml+xml':'ttml', 
     'x-flv':'flv', 
     'x-mp4-fragmented':'mp4', 
     'x-ms-sami':'sami', 
     'x-ms-wmv':'wmv', 
     'mpegurl':'m3u8', 
     'x-mpegurl':'m3u8', 
     'vnd.apple.mpegurl':'m3u8', 
     'dash+xml':'mpd', 
     'f4m+xml':'f4m', 
     'hds+xml':'f4m', 
     'vnd.ms-sstr+xml':'ism', 
     'quicktime':'mov', 
     'mp2t':'ts', 
     'x-wav':'wav'}.get(res, res)


def parse_codecs--- This code section failed: ---

 L.4208         0  LOAD_FAST                'codecs_str'
                2  POP_JUMP_IF_TRUE      8  'to 8'

 L.4209         4  BUILD_MAP_0           0 
                6  RETURN_VALUE     
              8_0  COME_FROM             2  '2'

 L.4210         8  LOAD_GLOBAL              list
               10  LOAD_GLOBAL              filter
               12  LOAD_CONST               None
               14  LOAD_GLOBAL              map

 L.4211        16  LOAD_LAMBDA              '<code_object <lambda>>'
               18  LOAD_STR                 'parse_codecs.<locals>.<lambda>'
               20  MAKE_FUNCTION_0          'Neither defaults, keyword-only args, annotations, nor closures'
               22  LOAD_FAST                'codecs_str'
               24  LOAD_METHOD              strip
               26  CALL_METHOD_0         0  '0 positional arguments'
               28  LOAD_METHOD              strip
               30  LOAD_STR                 ','
               32  CALL_METHOD_1         1  '1 positional argument'
               34  LOAD_METHOD              split
               36  LOAD_STR                 ','
               38  CALL_METHOD_1         1  '1 positional argument'
               40  CALL_FUNCTION_2       2  '2 positional arguments'
               42  CALL_FUNCTION_2       2  '2 positional arguments'
               44  CALL_FUNCTION_1       1  '1 positional argument'
               46  STORE_FAST               'split_codecs'

 L.4212        48  LOAD_CONST               (None, None)
               50  UNPACK_SEQUENCE_2     2 
               52  STORE_FAST               'vcodec'
               54  STORE_FAST               'acodec'

 L.4213        56  SETUP_LOOP          136  'to 136'
               58  LOAD_FAST                'split_codecs'
               60  GET_ITER         
             62_0  COME_FROM           132  '132'
             62_1  COME_FROM           114  '114'
             62_2  COME_FROM            96  '96'
               62  FOR_ITER            134  'to 134'
               64  STORE_FAST               'full_codec'

 L.4214        66  LOAD_FAST                'full_codec'
               68  LOAD_METHOD              split
               70  LOAD_STR                 '.'
               72  CALL_METHOD_1         1  '1 positional argument'
               74  LOAD_CONST               0
               76  BINARY_SUBSCR    
               78  STORE_FAST               'codec'

 L.4215        80  LOAD_FAST                'codec'
               82  LOAD_CONST               ('avc1', 'avc2', 'avc3', 'avc4', 'vp9', 'vp8', 'hev1', 'hev2', 'h263', 'h264', 'mp4v', 'hvc1', 'av01', 'theora')
               84  COMPARE_OP               in
               86  POP_JUMP_IF_FALSE    98  'to 98'

 L.4216        88  LOAD_FAST                'vcodec'
               90  POP_JUMP_IF_TRUE    132  'to 132'

 L.4217        92  LOAD_FAST                'full_codec'
               94  STORE_FAST               'vcodec'
               96  JUMP_BACK            62  'to 62'
             98_0  COME_FROM            86  '86'

 L.4218        98  LOAD_FAST                'codec'
              100  LOAD_CONST               ('mp4a', 'opus', 'vorbis', 'mp3', 'aac', 'ac-3', 'ec-3', 'eac3', 'dtsc', 'dtse', 'dtsh', 'dtsl')
              102  COMPARE_OP               in
              104  POP_JUMP_IF_FALSE   116  'to 116'

 L.4219       106  LOAD_FAST                'acodec'
              108  POP_JUMP_IF_TRUE    132  'to 132'

 L.4220       110  LOAD_FAST                'full_codec'
              112  STORE_FAST               'acodec'
              114  JUMP_BACK            62  'to 62'
            116_0  COME_FROM           104  '104'

 L.4222       116  LOAD_GLOBAL              write_string
              118  LOAD_STR                 'WARNING: Unknown codec %s\n'
              120  LOAD_FAST                'full_codec'
              122  BINARY_MODULO    
              124  LOAD_GLOBAL              sys
              126  LOAD_ATTR                stderr
              128  CALL_FUNCTION_2       2  '2 positional arguments'
              130  POP_TOP          
            132_0  COME_FROM           108  '108'
            132_1  COME_FROM            90  '90'
              132  JUMP_BACK            62  'to 62'
              134  POP_BLOCK        
            136_0  COME_FROM_LOOP       56  '56'

 L.4223       136  LOAD_FAST                'vcodec'
              138  POP_JUMP_IF_TRUE    176  'to 176'
              140  LOAD_FAST                'acodec'
              142  POP_JUMP_IF_TRUE    176  'to 176'

 L.4224       144  LOAD_GLOBAL              len
              146  LOAD_FAST                'split_codecs'
              148  CALL_FUNCTION_1       1  '1 positional argument'
              150  LOAD_CONST               2
              152  COMPARE_OP               ==
              154  POP_JUMP_IF_FALSE   194  'to 194'

 L.4226       156  LOAD_FAST                'split_codecs'
              158  LOAD_CONST               0
              160  BINARY_SUBSCR    

 L.4227       162  LOAD_FAST                'split_codecs'
              164  LOAD_CONST               1
              166  BINARY_SUBSCR    
              168  LOAD_CONST               ('vcodec', 'acodec')
              170  BUILD_CONST_KEY_MAP_2     2 
              172  RETURN_VALUE     
              174  JUMP_FORWARD        194  'to 194'
            176_0  COME_FROM           142  '142'
            176_1  COME_FROM           138  '138'

 L.4231       176  LOAD_FAST                'vcodec'
              178  JUMP_IF_TRUE_OR_POP   182  'to 182'
              180  LOAD_STR                 'none'
            182_0  COME_FROM           178  '178'

 L.4232       182  LOAD_FAST                'acodec'
              184  JUMP_IF_TRUE_OR_POP   188  'to 188'
              186  LOAD_STR                 'none'
            188_0  COME_FROM           184  '184'
              188  LOAD_CONST               ('vcodec', 'acodec')
              190  BUILD_CONST_KEY_MAP_2     2 
              192  RETURN_VALUE     
            194_0  COME_FROM           174  '174'
            194_1  COME_FROM           154  '154'

 L.4234       194  BUILD_MAP_0           0 
              196  RETURN_VALUE     
               -1  RETURN_LAST      

Parse error at or near `BUILD_MAP_0' instruction at offset 194


def urlhandle_detect_ext(url_handle):
    getheader = url_handle.headers.get
    cd = getheader('Content-Disposition')
    if cd:
        m = re.match('attachment;\\s*filename="(?P<filename>[^"]+)"', cd)
        if m:
            e = determine_ext((m.group('filename')), default_ext=None)
            if e:
                return e
    return mimetype2ext(getheader('Content-Type'))


def encode_data_uri(data, mime_type):
    return 'data:%s;base64,%s' % (mime_type, base64.b64encode(data).decode('ascii'))


def age_restricted(content_limit, age_limit):
    """ Returns True iff the content should be blocked """
    if age_limit is None:
        return False
    if content_limit is None:
        return False
    return age_limit < content_limit


def is_html(first_bytes):
    """ Detect whether a file contains HTML by examining its first bytes. """
    BOMS = [
     ('\ufeff', 'utf-8'),
     (b'\x00\x00\xfe\xff', 'utf-32-be'),
     (b'\xff\xfe\x00\x00', 'utf-32-le'),
     (b'\xff\xfe', 'utf-16-le'),
     (b'\xfe\xff', 'utf-16-be')]
    for bom, enc in BOMS:
        if first_bytes.startswith(bom):
            s = first_bytes[len(bom):].decode(enc, 'replace')
            break
    else:
        s = first_bytes.decode('utf-8', 'replace')
    return re.match('^\\s*<', s)


def determine_protocol(info_dict):
    protocol = info_dict.get('protocol')
    if protocol is not None:
        return protocol
    url = info_dict['url']
    if url.startswith('rtmp'):
        return 'rtmp'
    if url.startswith('mms'):
        return 'mms'
    if url.startswith('rtsp'):
        return 'rtsp'
    ext = determine_ext(url)
    if ext == 'm3u8':
        return 'm3u8'
    if ext == 'f4m':
        return 'f4m'
    return compat_urllib_parse_urlparse(url).scheme


def render_table(header_row, data):
    """ Render a list of rows, each as a list of values """
    table = [
     header_row] + data
    max_lens = [max((len(compat_str(v)) for v in col)) for col in zip(*table)]
    format_str = ' '.join(('%-' + compat_str(ml + 1) + 's' for ml in max_lens[:-1])) + '%s'
    return '\n'.join((format_str % tuple(row) for row in table))


def _match_one(filter_part, dct):
    COMPARISON_OPERATORS = {'<':operator.lt, 
     '<=':operator.le, 
     '>':operator.gt, 
     '>=':operator.ge, 
     '=':operator.eq, 
     '!=':operator.ne}
    operator_rex = re.compile('(?x)\\s*\n        (?P<key>[a-z_]+)\n        \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n        (?:\n            (?P<intval>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)|\n            (?P<quote>["\\\'])(?P<quotedstrval>(?:\\\\.|(?!(?P=quote)|\\\\).)+?)(?P=quote)|\n            (?P<strval>(?![0-9.])[a-z0-9A-Z]*)\n        )\n        \\s*$\n        ' % '|'.join(map(re.escape, COMPARISON_OPERATORS.keys())))
    m = operator_rex.search(filter_part)
    if m:
        op = COMPARISON_OPERATORS[m.group('op')]
        actual_value = dct.get(m.group('key'))
        if not (m.group('quotedstrval') is not None or m.group('strval') is not None):
            if not actual_value is not None and m.group('intval') is not None or isinstance(actual_value, compat_str):
                if m.group('op') not in ('=', '!='):
                    raise ValueError('Operator %s does not support string values!' % m.group('op'))
                comparison_value = m.group('quotedstrval') or m.group('strval') or m.group('intval')
                quote = m.group('quote')
                if quote is not None:
                    comparison_value = comparison_value.replace('\\%s' % quote, quote)
            else:
                try:
                    comparison_value = int(m.group('intval'))
                except ValueError:
                    comparison_value = parse_filesize(m.group('intval'))
                    if comparison_value is None:
                        comparison_value = parse_filesize(m.group('intval') + 'B')
                    if comparison_value is None:
                        raise ValueError('Invalid integer value %r in filter part %r' % (
                         m.group('intval'), filter_part))

            if actual_value is None:
                return m.group('none_inclusive')
            return op(actual_value, comparison_value)
    UNARY_OPERATORS = {'':lambda v: v is True if isinstance(v, bool) else v is not None,  '!':lambda v: v is False if isinstance(v, bool) else v is None}
    operator_rex = re.compile('(?x)\\s*\n        (?P<op>%s)\\s*(?P<key>[a-z_]+)\n        \\s*$\n        ' % '|'.join(map(re.escape, UNARY_OPERATORS.keys())))
    m = operator_rex.search(filter_part)
    if m:
        op = UNARY_OPERATORS[m.group('op')]
        actual_value = dct.get(m.group('key'))
        return op(actual_value)
    raise ValueError('Invalid filter part %r' % filter_part)


def match_str(filter_str, dct):
    """ Filter a dictionary with a simple string syntax. Returns True (=passes filter) or false """
    return all((_match_one(filter_part, dct) for filter_part in filter_str.split('&')))


def match_filter_func(filter_str):

    def _match_func(info_dict):
        if match_str(filter_str, info_dict):
            return
        video_title = info_dict.get('title', info_dict.get('id', 'video'))
        return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)

    return _match_func


def parse_dfxp_time_expr(time_expr):
    if not time_expr:
        return
    mobj = re.match('^(?P<time_offset>\\d+(?:\\.\\d+)?)s?$', time_expr)
    if mobj:
        return float(mobj.group('time_offset'))
    mobj = re.match('^(\\d+):(\\d\\d):(\\d\\d(?:(?:\\.|:)\\d+)?)$', time_expr)
    if mobj:
        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3).replace(':', '.'))


def srt_subtitles_timecode(seconds):
    return '%02d:%02d:%02d,%03d' % (seconds / 3600, seconds % 3600 / 60, seconds % 60, seconds % 1 * 1000)


def dfxp2srt(dfxp_data):
    """
    @param dfxp_data A bytes-like object containing DFXP data
    @returns A unicode object containing converted SRT data
    """
    LEGACY_NAMESPACES = (
     (
      'http://www.w3.org/ns/ttml',
      [
       'http://www.w3.org/2004/11/ttaf1',
       'http://www.w3.org/2006/04/ttaf1',
       'http://www.w3.org/2006/10/ttaf1']),
     (
      'http://www.w3.org/ns/ttml#styling',
      [
       'http://www.w3.org/ns/ttml#style']))
    SUPPORTED_STYLING = [
     'color',
     'fontFamily',
     'fontSize',
     'fontStyle',
     'fontWeight',
     'textDecoration']
    _x = functools.partial(xpath_with_ns, ns_map={'xml':'http://www.w3.org/XML/1998/namespace', 
     'ttml':'http://www.w3.org/ns/ttml', 
     'tts':'http://www.w3.org/ns/ttml#styling'})
    styles = {}
    default_style = {}

    class TTMLPElementParser(object):
        _out = ''
        _unclosed_elements = []
        _applied_styles = []

        def start(self, tag, attrib):
            if tag in (_x('ttml:br'), 'br'):
                self._out += '\n'
            else:
                unclosed_elements = []
                style = {}
                element_style_id = attrib.get('style')
                if default_style:
                    style.update(default_style)
                if element_style_id:
                    style.update(styles.get(element_style_id, {}))
                for prop in SUPPORTED_STYLING:
                    prop_val = attrib.get(_x('tts:' + prop))
                    if prop_val:
                        style[prop] = prop_val

                if style:
                    font = ''
                    for k, v in sorted(style.items()):
                        if self._applied_styles:
                            if self._applied_styles[(-1)].get(k) == v:
                                continue
                        if k == 'color':
                            font += ' color="%s"' % v
                        else:
                            if k == 'fontSize':
                                font += ' size="%s"' % v
                            else:
                                if k == 'fontFamily':
                                    font += ' face="%s"' % v
                        if k == 'fontWeight' and v == 'bold':
                            self._out += '<b>'
                            unclosed_elements.append('b')
                        else:
                            if k == 'fontStyle' and v == 'italic':
                                self._out += '<i>'
                                unclosed_elements.append('i')
                            else:
                                if k == 'textDecoration':
                                    if v == 'underline':
                                        self._out += '<u>'
                                        unclosed_elements.append('u')

                    if font:
                        self._out += '<font' + font + '>'
                        unclosed_elements.append('font')
                    applied_style = {}
                    if self._applied_styles:
                        applied_style.update(self._applied_styles[(-1)])
                    applied_style.update(style)
                    self._applied_styles.append(applied_style)
                self._unclosed_elements.append(unclosed_elements)

        def end(self, tag):
            if tag not in (_x('ttml:br'), 'br'):
                unclosed_elements = self._unclosed_elements.pop()
                for element in reversed(unclosed_elements):
                    self._out += '</%s>' % element

                if unclosed_elements:
                    if self._applied_styles:
                        self._applied_styles.pop()

        def data(self, data):
            self._out += data

        def close(self):
            return self._out.strip()

    def parse_node(node):
        target = TTMLPElementParser()
        parser = xml.etree.ElementTree.XMLParser(target=target)
        parser.feed(xml.etree.ElementTree.tostring(node))
        return parser.close()

    for k, v in LEGACY_NAMESPACES:
        for ns in v:
            dfxp_data = dfxp_data.replace(ns, k)

    dfxp = compat_etree_fromstring(dfxp_data)
    out = []
    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall('.//p')
    if not paras:
        raise ValueError('Invalid dfxp/TTML subtitle')
    repeat = False
    while True:
        for style in dfxp.findall(_x('.//ttml:style')):
            style_id = style.get('id') or style.get(_x('xml:id'))
            if not style_id:
                continue
            else:
                parent_style_id = style.get('style')
            if parent_style_id:
                if parent_style_id not in styles:
                    repeat = True
                    continue
                else:
                    styles[style_id] = styles[parent_style_id].copy()
            else:
                for prop in SUPPORTED_STYLING:
                    prop_val = style.get(_x('tts:' + prop))
                    if prop_val:
                        styles.setdefault(style_id, {})[prop] = prop_val

        if repeat:
            repeat = False
        else:
            break

    for p in ('body', 'div'):
        ele = xpath_element(dfxp, [_x('.//ttml:' + p), './/' + p])
        if ele is None:
            continue
        else:
            style = styles.get(ele.get('style'))
        if not style:
            continue
        else:
            default_style.update(style)

    for para, index in zip(paras, itertools.count(1)):
        begin_time = parse_dfxp_time_expr(para.attrib.get('begin'))
        end_time = parse_dfxp_time_expr(para.attrib.get('end'))
        dur = parse_dfxp_time_expr(para.attrib.get('dur'))
        if begin_time is None:
            continue
        if not end_time:
            if not dur:
                continue
            else:
                end_time = begin_time + dur
        else:
            out.append('%d\n%s --> %s\n%s\n\n' % (
             index,
             srt_subtitles_timecode(begin_time),
             srt_subtitles_timecode(end_time),
             parse_node(para)))

    return ''.join(out)


def cli_option(params, command_option, param):
    param = params.get(param)
    if param:
        param = compat_str(param)
    if param is not None:
        return [command_option, param]
    return []


def cli_bool_option(params, command_option, param, true_value='true', false_value='false', separator=None):
    param = params.get(param)
    if param is None:
        return []
    assert isinstance(param, bool)
    if separator:
        return [command_option + separator + (true_value if param else false_value)]
    return [command_option, true_value if param else false_value]


def cli_valueless_option(params, command_option, param, expected_value=True):
    param = params.get(param)
    if param == expected_value:
        return [command_option]
    return []


def cli_configuration_args(params, param, default=[]):
    ex_args = params.get(param)
    if ex_args is None:
        return default
    assert isinstance(ex_args, list)
    return ex_args


class ISO639Utils(object):
    _lang_map = {'aa':'aar', 
     'ab':'abk', 
     'ae':'ave', 
     'af':'afr', 
     'ak':'aka', 
     'am':'amh', 
     'an':'arg', 
     'ar':'ara', 
     'as':'asm', 
     'av':'ava', 
     'ay':'aym', 
     'az':'aze', 
     'ba':'bak', 
     'be':'bel', 
     'bg':'bul', 
     'bh':'bih', 
     'bi':'bis', 
     'bm':'bam', 
     'bn':'ben', 
     'bo':'bod', 
     'br':'bre', 
     'bs':'bos', 
     'ca':'cat', 
     'ce':'che', 
     'ch':'cha', 
     'co':'cos', 
     'cr':'cre', 
     'cs':'ces', 
     'cu':'chu', 
     'cv':'chv', 
     'cy':'cym', 
     'da':'dan', 
     'de':'deu', 
     'dv':'div', 
     'dz':'dzo', 
     'ee':'ewe', 
     'el':'ell', 
     'en':'eng', 
     'eo':'epo', 
     'es':'spa', 
     'et':'est', 
     'eu':'eus', 
     'fa':'fas', 
     'ff':'ful', 
     'fi':'fin', 
     'fj':'fij', 
     'fo':'fao', 
     'fr':'fra', 
     'fy':'fry', 
     'ga':'gle', 
     'gd':'gla', 
     'gl':'glg', 
     'gn':'grn', 
     'gu':'guj', 
     'gv':'glv', 
     'ha':'hau', 
     'he':'heb', 
     'iw':'heb', 
     'hi':'hin', 
     'ho':'hmo', 
     'hr':'hrv', 
     'ht':'hat', 
     'hu':'hun', 
     'hy':'hye', 
     'hz':'her', 
     'ia':'ina', 
     'id':'ind', 
     'in':'ind', 
     'ie':'ile', 
     'ig':'ibo', 
     'ii':'iii', 
     'ik':'ipk', 
     'io':'ido', 
     'is':'isl', 
     'it':'ita', 
     'iu':'iku', 
     'ja':'jpn', 
     'jv':'jav', 
     'ka':'kat', 
     'kg':'kon', 
     'ki':'kik', 
     'kj':'kua', 
     'kk':'kaz', 
     'kl':'kal', 
     'km':'khm', 
     'kn':'kan', 
     'ko':'kor', 
     'kr':'kau', 
     'ks':'kas', 
     'ku':'kur', 
     'kv':'kom', 
     'kw':'cor', 
     'ky':'kir', 
     'la':'lat', 
     'lb':'ltz', 
     'lg':'lug', 
     'li':'lim', 
     'ln':'lin', 
     'lo':'lao', 
     'lt':'lit', 
     'lu':'lub', 
     'lv':'lav', 
     'mg':'mlg', 
     'mh':'mah', 
     'mi':'mri', 
     'mk':'mkd', 
     'ml':'mal', 
     'mn':'mon', 
     'mr':'mar', 
     'ms':'msa', 
     'mt':'mlt', 
     'my':'mya', 
     'na':'nau', 
     'nb':'nob', 
     'nd':'nde', 
     'ne':'nep', 
     'ng':'ndo', 
     'nl':'nld', 
     'nn':'nno', 
     'no':'nor', 
     'nr':'nbl', 
     'nv':'nav', 
     'ny':'nya', 
     'oc':'oci', 
     'oj':'oji', 
     'om':'orm', 
     'or':'ori', 
     'os':'oss', 
     'pa':'pan', 
     'pi':'pli', 
     'pl':'pol', 
     'ps':'pus', 
     'pt':'por', 
     'qu':'que', 
     'rm':'roh', 
     'rn':'run', 
     'ro':'ron', 
     'ru':'rus', 
     'rw':'kin', 
     'sa':'san', 
     'sc':'srd', 
     'sd':'snd', 
     'se':'sme', 
     'sg':'sag', 
     'si':'sin', 
     'sk':'slk', 
     'sl':'slv', 
     'sm':'smo', 
     'sn':'sna', 
     'so':'som', 
     'sq':'sqi', 
     'sr':'srp', 
     'ss':'ssw', 
     'st':'sot', 
     'su':'sun', 
     'sv':'swe', 
     'sw':'swa', 
     'ta':'tam', 
     'te':'tel', 
     'tg':'tgk', 
     'th':'tha', 
     'ti':'tir', 
     'tk':'tuk', 
     'tl':'tgl', 
     'tn':'tsn', 
     'to':'ton', 
     'tr':'tur', 
     'ts':'tso', 
     'tt':'tat', 
     'tw':'twi', 
     'ty':'tah', 
     'ug':'uig', 
     'uk':'ukr', 
     'ur':'urd', 
     'uz':'uzb', 
     've':'ven', 
     'vi':'vie', 
     'vo':'vol', 
     'wa':'wln', 
     'wo':'wol', 
     'xh':'xho', 
     'yi':'yid', 
     'ji':'yid', 
     'yo':'yor', 
     'za':'zha', 
     'zh':'zho', 
     'zu':'zul'}

    @classmethod
    def short2long(cls, code):
        """Convert language code from ISO 639-1 to ISO 639-2/T"""
        return cls._lang_map.get(code[:2])

    @classmethod
    def long2short(cls, code):
        """Convert language code from ISO 639-2/T to ISO 639-1"""
        for short_name, long_name in cls._lang_map.items():
            if long_name == code:
                return short_name


class ISO3166Utils(object):
    _country_map = {'AF':'Afghanistan', 
     'AX':'Åland Islands', 
     'AL':'Albania', 
     'DZ':'Algeria', 
     'AS':'American Samoa', 
     'AD':'Andorra', 
     'AO':'Angola', 
     'AI':'Anguilla', 
     'AQ':'Antarctica', 
     'AG':'Antigua and Barbuda', 
     'AR':'Argentina', 
     'AM':'Armenia', 
     'AW':'Aruba', 
     'AU':'Australia', 
     'AT':'Austria', 
     'AZ':'Azerbaijan', 
     'BS':'Bahamas', 
     'BH':'Bahrain', 
     'BD':'Bangladesh', 
     'BB':'Barbados', 
     'BY':'Belarus', 
     'BE':'Belgium', 
     'BZ':'Belize', 
     'BJ':'Benin', 
     'BM':'Bermuda', 
     'BT':'Bhutan', 
     'BO':'Bolivia, Plurinational State of', 
     'BQ':'Bonaire, Sint Eustatius and Saba', 
     'BA':'Bosnia and Herzegovina', 
     'BW':'Botswana', 
     'BV':'Bouvet Island', 
     'BR':'Brazil', 
     'IO':'British Indian Ocean Territory', 
     'BN':'Brunei Darussalam', 
     'BG':'Bulgaria', 
     'BF':'Burkina Faso', 
     'BI':'Burundi', 
     'KH':'Cambodia', 
     'CM':'Cameroon', 
     'CA':'Canada', 
     'CV':'Cape Verde', 
     'KY':'Cayman Islands', 
     'CF':'Central African Republic', 
     'TD':'Chad', 
     'CL':'Chile', 
     'CN':'China', 
     'CX':'Christmas Island', 
     'CC':'Cocos (Keeling) Islands', 
     'CO':'Colombia', 
     'KM':'Comoros', 
     'CG':'Congo', 
     'CD':'Congo, the Democratic Republic of the', 
     'CK':'Cook Islands', 
     'CR':'Costa Rica', 
     'CI':"Côte d'Ivoire", 
     'HR':'Croatia', 
     'CU':'Cuba', 
     'CW':'Curaçao', 
     'CY':'Cyprus', 
     'CZ':'Czech Republic', 
     'DK':'Denmark', 
     'DJ':'Djibouti', 
     'DM':'Dominica', 
     'DO':'Dominican Republic', 
     'EC':'Ecuador', 
     'EG':'Egypt', 
     'SV':'El Salvador', 
     'GQ':'Equatorial Guinea', 
     'ER':'Eritrea', 
     'EE':'Estonia', 
     'ET':'Ethiopia', 
     'FK':'Falkland Islands (Malvinas)', 
     'FO':'Faroe Islands', 
     'FJ':'Fiji', 
     'FI':'Finland', 
     'FR':'France', 
     'GF':'French Guiana', 
     'PF':'French Polynesia', 
     'TF':'French Southern Territories', 
     'GA':'Gabon', 
     'GM':'Gambia', 
     'GE':'Georgia', 
     'DE':'Germany', 
     'GH':'Ghana', 
     'GI':'Gibraltar', 
     'GR':'Greece', 
     'GL':'Greenland', 
     'GD':'Grenada', 
     'GP':'Guadeloupe', 
     'GU':'Guam', 
     'GT':'Guatemala', 
     'GG':'Guernsey', 
     'GN':'Guinea', 
     'GW':'Guinea-Bissau', 
     'GY':'Guyana', 
     'HT':'Haiti', 
     'HM':'Heard Island and McDonald Islands', 
     'VA':'Holy See (Vatican City State)', 
     'HN':'Honduras', 
     'HK':'Hong Kong', 
     'HU':'Hungary', 
     'IS':'Iceland', 
     'IN':'India', 
     'ID':'Indonesia', 
     'IR':'Iran, Islamic Republic of', 
     'IQ':'Iraq', 
     'IE':'Ireland', 
     'IM':'Isle of Man', 
     'IL':'Israel', 
     'IT':'Italy', 
     'JM':'Jamaica', 
     'JP':'Japan', 
     'JE':'Jersey', 
     'JO':'Jordan', 
     'KZ':'Kazakhstan', 
     'KE':'Kenya', 
     'KI':'Kiribati', 
     'KP':"Korea, Democratic People's Republic of", 
     'KR':'Korea, Republic of', 
     'KW':'Kuwait', 
     'KG':'Kyrgyzstan', 
     'LA':"Lao People's Democratic Republic", 
     'LV':'Latvia', 
     'LB':'Lebanon', 
     'LS':'Lesotho', 
     'LR':'Liberia', 
     'LY':'Libya', 
     'LI':'Liechtenstein', 
     'LT':'Lithuania', 
     'LU':'Luxembourg', 
     'MO':'Macao', 
     'MK':'Macedonia, the Former Yugoslav Republic of', 
     'MG':'Madagascar', 
     'MW':'Malawi', 
     'MY':'Malaysia', 
     'MV':'Maldives', 
     'ML':'Mali', 
     'MT':'Malta', 
     'MH':'Marshall Islands', 
     'MQ':'Martinique', 
     'MR':'Mauritania', 
     'MU':'Mauritius', 
     'YT':'Mayotte', 
     'MX':'Mexico', 
     'FM':'Micronesia, Federated States of', 
     'MD':'Moldova, Republic of', 
     'MC':'Monaco', 
     'MN':'Mongolia', 
     'ME':'Montenegro', 
     'MS':'Montserrat', 
     'MA':'Morocco', 
     'MZ':'Mozambique', 
     'MM':'Myanmar', 
     'NA':'Namibia', 
     'NR':'Nauru', 
     'NP':'Nepal', 
     'NL':'Netherlands', 
     'NC':'New Caledonia', 
     'NZ':'New Zealand', 
     'NI':'Nicaragua', 
     'NE':'Niger', 
     'NG':'Nigeria', 
     'NU':'Niue', 
     'NF':'Norfolk Island', 
     'MP':'Northern Mariana Islands', 
     'NO':'Norway', 
     'OM':'Oman', 
     'PK':'Pakistan', 
     'PW':'Palau', 
     'PS':'Palestine, State of', 
     'PA':'Panama', 
     'PG':'Papua New Guinea', 
     'PY':'Paraguay', 
     'PE':'Peru', 
     'PH':'Philippines', 
     'PN':'Pitcairn', 
     'PL':'Poland', 
     'PT':'Portugal', 
     'PR':'Puerto Rico', 
     'QA':'Qatar', 
     'RE':'Réunion', 
     'RO':'Romania', 
     'RU':'Russian Federation', 
     'RW':'Rwanda', 
     'BL':'Saint Barthélemy', 
     'SH':'Saint Helena, Ascension and Tristan da Cunha', 
     'KN':'Saint Kitts and Nevis', 
     'LC':'Saint Lucia', 
     'MF':'Saint Martin (French part)', 
     'PM':'Saint Pierre and Miquelon', 
     'VC':'Saint Vincent and the Grenadines', 
     'WS':'Samoa', 
     'SM':'San Marino', 
     'ST':'Sao Tome and Principe', 
     'SA':'Saudi Arabia', 
     'SN':'Senegal', 
     'RS':'Serbia', 
     'SC':'Seychelles', 
     'SL':'Sierra Leone', 
     'SG':'Singapore', 
     'SX':'Sint Maarten (Dutch part)', 
     'SK':'Slovakia', 
     'SI':'Slovenia', 
     'SB':'Solomon Islands', 
     'SO':'Somalia', 
     'ZA':'South Africa', 
     'GS':'South Georgia and the South Sandwich Islands', 
     'SS':'South Sudan', 
     'ES':'Spain', 
     'LK':'Sri Lanka', 
     'SD':'Sudan', 
     'SR':'Suriname', 
     'SJ':'Svalbard and Jan Mayen', 
     'SZ':'Swaziland', 
     'SE':'Sweden', 
     'CH':'Switzerland', 
     'SY':'Syrian Arab Republic', 
     'TW':'Taiwan, Province of China', 
     'TJ':'Tajikistan', 
     'TZ':'Tanzania, United Republic of', 
     'TH':'Thailand', 
     'TL':'Timor-Leste', 
     'TG':'Togo', 
     'TK':'Tokelau', 
     'TO':'Tonga', 
     'TT':'Trinidad and Tobago', 
     'TN':'Tunisia', 
     'TR':'Turkey', 
     'TM':'Turkmenistan', 
     'TC':'Turks and Caicos Islands', 
     'TV':'Tuvalu', 
     'UG':'Uganda', 
     'UA':'Ukraine', 
     'AE':'United Arab Emirates', 
     'GB':'United Kingdom', 
     'US':'United States', 
     'UM':'United States Minor Outlying Islands', 
     'UY':'Uruguay', 
     'UZ':'Uzbekistan', 
     'VU':'Vanuatu', 
     'VE':'Venezuela, Bolivarian Republic of', 
     'VN':'Viet Nam', 
     'VG':'Virgin Islands, British', 
     'VI':'Virgin Islands, U.S.', 
     'WF':'Wallis and Futuna', 
     'EH':'Western Sahara', 
     'YE':'Yemen', 
     'ZM':'Zambia', 
     'ZW':'Zimbabwe'}

    @classmethod
    def short2full(cls, code):
        """Convert an ISO 3166-2 country code to the corresponding full name"""
        return cls._country_map.get(code.upper())


class GeoUtils(object):
    _country_ip_map = {'AD':'46.172.224.0/19', 
     'AE':'94.200.0.0/13', 
     'AF':'149.54.0.0/17', 
     'AG':'209.59.64.0/18', 
     'AI':'204.14.248.0/21', 
     'AL':'46.99.0.0/16', 
     'AM':'46.70.0.0/15', 
     'AO':'105.168.0.0/13', 
     'AP':'182.50.184.0/21', 
     'AQ':'23.154.160.0/24', 
     'AR':'181.0.0.0/12', 
     'AS':'202.70.112.0/20', 
     'AT':'77.116.0.0/14', 
     'AU':'1.128.0.0/11', 
     'AW':'181.41.0.0/18', 
     'AX':'185.217.4.0/22', 
     'AZ':'5.197.0.0/16', 
     'BA':'31.176.128.0/17', 
     'BB':'65.48.128.0/17', 
     'BD':'114.130.0.0/16', 
     'BE':'57.0.0.0/8', 
     'BF':'102.178.0.0/15', 
     'BG':'95.42.0.0/15', 
     'BH':'37.131.0.0/17', 
     'BI':'154.117.192.0/18', 
     'BJ':'137.255.0.0/16', 
     'BL':'185.212.72.0/23', 
     'BM':'196.12.64.0/18', 
     'BN':'156.31.0.0/16', 
     'BO':'161.56.0.0/16', 
     'BQ':'161.0.80.0/20', 
     'BR':'191.128.0.0/12', 
     'BS':'24.51.64.0/18', 
     'BT':'119.2.96.0/19', 
     'BW':'168.167.0.0/16', 
     'BY':'178.120.0.0/13', 
     'BZ':'179.42.192.0/18', 
     'CA':'99.224.0.0/11', 
     'CD':'41.243.0.0/16', 
     'CF':'197.242.176.0/21', 
     'CG':'160.113.0.0/16', 
     'CH':'85.0.0.0/13', 
     'CI':'102.136.0.0/14', 
     'CK':'202.65.32.0/19', 
     'CL':'152.172.0.0/14', 
     'CM':'102.244.0.0/14', 
     'CN':'36.128.0.0/10', 
     'CO':'181.240.0.0/12', 
     'CR':'201.192.0.0/12', 
     'CU':'152.206.0.0/15', 
     'CV':'165.90.96.0/19', 
     'CW':'190.88.128.0/17', 
     'CY':'31.153.0.0/16', 
     'CZ':'88.100.0.0/14', 
     'DE':'53.0.0.0/8', 
     'DJ':'197.241.0.0/17', 
     'DK':'87.48.0.0/12', 
     'DM':'192.243.48.0/20', 
     'DO':'152.166.0.0/15', 
     'DZ':'41.96.0.0/12', 
     'EC':'186.68.0.0/15', 
     'EE':'90.190.0.0/15', 
     'EG':'156.160.0.0/11', 
     'ER':'196.200.96.0/20', 
     'ES':'88.0.0.0/11', 
     'ET':'196.188.0.0/14', 
     'EU':'2.16.0.0/13', 
     'FI':'91.152.0.0/13', 
     'FJ':'144.120.0.0/16', 
     'FK':'80.73.208.0/21', 
     'FM':'119.252.112.0/20', 
     'FO':'88.85.32.0/19', 
     'FR':'90.0.0.0/9', 
     'GA':'41.158.0.0/15', 
     'GB':'25.0.0.0/8', 
     'GD':'74.122.88.0/21', 
     'GE':'31.146.0.0/16', 
     'GF':'161.22.64.0/18', 
     'GG':'62.68.160.0/19', 
     'GH':'154.160.0.0/12', 
     'GI':'95.164.0.0/16', 
     'GL':'88.83.0.0/19', 
     'GM':'160.182.0.0/15', 
     'GN':'197.149.192.0/18', 
     'GP':'104.250.0.0/19', 
     'GQ':'105.235.224.0/20', 
     'GR':'94.64.0.0/13', 
     'GT':'168.234.0.0/16', 
     'GU':'168.123.0.0/16', 
     'GW':'197.214.80.0/20', 
     'GY':'181.41.64.0/18', 
     'HK':'113.252.0.0/14', 
     'HN':'181.210.0.0/16', 
     'HR':'93.136.0.0/13', 
     'HT':'148.102.128.0/17', 
     'HU':'84.0.0.0/14', 
     'ID':'39.192.0.0/10', 
     'IE':'87.32.0.0/12', 
     'IL':'79.176.0.0/13', 
     'IM':'5.62.80.0/20', 
     'IN':'117.192.0.0/10', 
     'IO':'203.83.48.0/21', 
     'IQ':'37.236.0.0/14', 
     'IR':'2.176.0.0/12', 
     'IS':'82.221.0.0/16', 
     'IT':'79.0.0.0/10', 
     'JE':'87.244.64.0/18', 
     'JM':'72.27.0.0/17', 
     'JO':'176.29.0.0/16', 
     'JP':'133.0.0.0/8', 
     'KE':'105.48.0.0/12', 
     'KG':'158.181.128.0/17', 
     'KH':'36.37.128.0/17', 
     'KI':'103.25.140.0/22', 
     'KM':'197.255.224.0/20', 
     'KN':'198.167.192.0/19', 
     'KP':'175.45.176.0/22', 
     'KR':'175.192.0.0/10', 
     'KW':'37.36.0.0/14', 
     'KY':'64.96.0.0/15', 
     'KZ':'2.72.0.0/13', 
     'LA':'115.84.64.0/18', 
     'LB':'178.135.0.0/16', 
     'LC':'24.92.144.0/20', 
     'LI':'82.117.0.0/19', 
     'LK':'112.134.0.0/15', 
     'LR':'102.183.0.0/16', 
     'LS':'129.232.0.0/17', 
     'LT':'78.56.0.0/13', 
     'LU':'188.42.0.0/16', 
     'LV':'46.109.0.0/16', 
     'LY':'41.252.0.0/14', 
     'MA':'105.128.0.0/11', 
     'MC':'88.209.64.0/18', 
     'MD':'37.246.0.0/16', 
     'ME':'178.175.0.0/17', 
     'MF':'74.112.232.0/21', 
     'MG':'154.126.0.0/17', 
     'MH':'117.103.88.0/21', 
     'MK':'77.28.0.0/15', 
     'ML':'154.118.128.0/18', 
     'MM':'37.111.0.0/17', 
     'MN':'49.0.128.0/17', 
     'MO':'60.246.0.0/16', 
     'MP':'202.88.64.0/20', 
     'MQ':'109.203.224.0/19', 
     'MR':'41.188.64.0/18', 
     'MS':'208.90.112.0/22', 
     'MT':'46.11.0.0/16', 
     'MU':'105.16.0.0/12', 
     'MV':'27.114.128.0/18', 
     'MW':'102.70.0.0/15', 
     'MX':'187.192.0.0/11', 
     'MY':'175.136.0.0/13', 
     'MZ':'197.218.0.0/15', 
     'NA':'41.182.0.0/16', 
     'NC':'101.101.0.0/18', 
     'NE':'197.214.0.0/18', 
     'NF':'203.17.240.0/22', 
     'NG':'105.112.0.0/12', 
     'NI':'186.76.0.0/15', 
     'NL':'145.96.0.0/11', 
     'NO':'84.208.0.0/13', 
     'NP':'36.252.0.0/15', 
     'NR':'203.98.224.0/19', 
     'NU':'49.156.48.0/22', 
     'NZ':'49.224.0.0/14', 
     'OM':'5.36.0.0/15', 
     'PA':'186.72.0.0/15', 
     'PE':'186.160.0.0/14', 
     'PF':'123.50.64.0/18', 
     'PG':'124.240.192.0/19', 
     'PH':'49.144.0.0/13', 
     'PK':'39.32.0.0/11', 
     'PL':'83.0.0.0/11', 
     'PM':'70.36.0.0/20', 
     'PR':'66.50.0.0/16', 
     'PS':'188.161.0.0/16', 
     'PT':'85.240.0.0/13', 
     'PW':'202.124.224.0/20', 
     'PY':'181.120.0.0/14', 
     'QA':'37.210.0.0/15', 
     'RE':'102.35.0.0/16', 
     'RO':'79.112.0.0/13', 
     'RS':'93.86.0.0/15', 
     'RU':'5.136.0.0/13', 
     'RW':'41.186.0.0/16', 
     'SA':'188.48.0.0/13', 
     'SB':'202.1.160.0/19', 
     'SC':'154.192.0.0/11', 
     'SD':'102.120.0.0/13', 
     'SE':'78.64.0.0/12', 
     'SG':'8.128.0.0/10', 
     'SI':'188.196.0.0/14', 
     'SK':'78.98.0.0/15', 
     'SL':'102.143.0.0/17', 
     'SM':'89.186.32.0/19', 
     'SN':'41.82.0.0/15', 
     'SO':'154.115.192.0/18', 
     'SR':'186.179.128.0/17', 
     'SS':'105.235.208.0/21', 
     'ST':'197.159.160.0/19', 
     'SV':'168.243.0.0/16', 
     'SX':'190.102.0.0/20', 
     'SY':'5.0.0.0/16', 
     'SZ':'41.84.224.0/19', 
     'TC':'65.255.48.0/20', 
     'TD':'154.68.128.0/19', 
     'TG':'196.168.0.0/14', 
     'TH':'171.96.0.0/13', 
     'TJ':'85.9.128.0/18', 
     'TK':'27.96.24.0/21', 
     'TL':'180.189.160.0/20', 
     'TM':'95.85.96.0/19', 
     'TN':'197.0.0.0/11', 
     'TO':'175.176.144.0/21', 
     'TR':'78.160.0.0/11', 
     'TT':'186.44.0.0/15', 
     'TV':'202.2.96.0/19', 
     'TW':'120.96.0.0/11', 
     'TZ':'156.156.0.0/14', 
     'UA':'37.52.0.0/14', 
     'UG':'102.80.0.0/13', 
     'US':'6.0.0.0/8', 
     'UY':'167.56.0.0/13', 
     'UZ':'84.54.64.0/18', 
     'VA':'212.77.0.0/19', 
     'VC':'207.191.240.0/21', 
     'VE':'186.88.0.0/13', 
     'VG':'66.81.192.0/20', 
     'VI':'146.226.0.0/16', 
     'VN':'14.160.0.0/11', 
     'VU':'202.80.32.0/20', 
     'WF':'117.20.32.0/21', 
     'WS':'202.4.32.0/19', 
     'YE':'134.35.0.0/16', 
     'YT':'41.242.116.0/22', 
     'ZA':'41.0.0.0/11', 
     'ZM':'102.144.0.0/13', 
     'ZW':'102.177.192.0/18'}

    @classmethod
    def random_ipv4(cls, code_or_block):
        if len(code_or_block) == 2:
            block = cls._country_ip_map.get(code_or_block.upper())
            if not block:
                return
        else:
            block = code_or_block
        addr, preflen = block.split('/')
        addr_min = compat_struct_unpack('!L', socket.inet_aton(addr))[0]
        addr_max = addr_min | 4294967295 >> int(preflen)
        return compat_str(socket.inet_ntoa(compat_struct_pack('!L', random.randint(addr_min, addr_max))))


class PerRequestProxyHandler(compat_urllib_request.ProxyHandler):

    def __init__(self, proxies=None):
        for type in ('http', 'https'):
            setattr(self, '%s_open' % type, lambda r, proxy='__noproxy__', type=type, meth=self.proxy_open: meth(r, proxy, type))

        compat_urllib_request.ProxyHandler.__init__(self, proxies)

    def proxy_open(self, req, proxy, type):
        req_proxy = req.headers.get('Ytdl-request-proxy')
        if req_proxy is not None:
            proxy = req_proxy
            del req.headers['Ytdl-request-proxy']
        if proxy == '__noproxy__':
            return
        if compat_urlparse.urlparse(proxy).scheme.lower() in ('socks', 'socks4', 'socks4a',
                                                              'socks5'):
            req.add_header('Ytdl-socks-proxy', proxy)
            return
        return compat_urllib_request.ProxyHandler.proxy_open(self, req, proxy, type)


def long_to_bytes(n, blocksize=0):
    """long_to_bytes(n:long, blocksize:int) : string
    Convert a long integer to a byte string.

    If optional blocksize is given and greater than zero, pad the front of the
    byte string with binary zeros so that the length is a multiple of
    blocksize.
    """
    s = ''
    n = int(n)
    while n > 0:
        s = compat_struct_pack('>I', n & 4294967295) + s
        n = n >> 32

    for i in range(len(s)):
        if s[i] != 0:
            break
    else:
        s = '\x00'
        i = 0
    s = s[i:]
    if blocksize > 0:
        if len(s) % blocksize:
            s = (blocksize - len(s) % blocksize) * '\x00' + s
    return s


def bytes_to_long(s):
    """bytes_to_long(string) : long
    Convert a byte string to a long integer.

    This is (essentially) the inverse of long_to_bytes().
    """
    acc = 0
    length = len(s)
    if length % 4:
        extra = 4 - length % 4
        s = '\x00' * extra + s
        length = length + extra
    for i in range(0, length, 4):
        acc = (acc << 32) + compat_struct_unpack('>I', s[i:i + 4])[0]

    return acc


def ohdave_rsa_encrypt(data, exponent, modulus):
    """
    Implement OHDave's RSA algorithm. See http://www.ohdave.com/rsa/

    Input:
        data: data to encrypt, bytes-like object
        exponent, modulus: parameter e and N of RSA algorithm, both integer
    Output: hex string of encrypted data

    Limitation: supports one block encryption only
    """
    payload = int(binascii.hexlify(data[::-1]), 16)
    encrypted = pow(payload, exponent, modulus)
    return '%x' % encrypted


def pkcs1pad(data, length):
    """
    Padding input data with PKCS#1 scheme

    @param {int[]} data        input data
    @param {int}   length      target length
    @returns {int[]}           padded data
    """
    if len(data) > length - 11:
        raise ValueError('Input data too long for PKCS#1 padding')
    pseudo_random = [random.randint(0, 254) for _ in range(length - len(data) - 3)]
    return [
     0, 2] + pseudo_random + [0] + data


def encode_base_n(num, n, table=None):
    FULL_TABLE = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
    if not table:
        table = FULL_TABLE[:n]
    if n > len(table):
        raise ValueError('base %d exceeds table length %d' % (n, len(table)))
    if num == 0:
        return table[0]
    ret = ''
    while num:
        ret = table[(num % n)] + ret
        num = num // n

    return ret


def decode_packed_codes(code):
    mobj = re.search(PACKED_CODES_RE, code)
    obfuscated_code, base, count, symbols = mobj.groups()
    base = int(base)
    count = int(count)
    symbols = symbols.split('|')
    symbol_table = {}
    while count:
        count -= 1
        base_n_count = encode_base_n(count, base)
        symbol_table[base_n_count] = symbols[count] or base_n_count

    return re.sub('\\b(\\w+)\\b', lambda mobj: symbol_table[mobj.group(0)], obfuscated_code)


def caesar(s, alphabet, shift):
    if shift == 0:
        return s
    l = len(alphabet)
    return ''.join(((alphabet[((alphabet.index(c) + shift) % l)] if c in alphabet else c) for c in s))


def rot47(s):
    return caesar(s, '!"#$%&\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~', 47)


def parse_m3u8_attributes(attrib):
    info = {}
    for key, val in re.findall('(?P<key>[A-Z0-9-]+)=(?P<val>"[^"]+"|[^",]+)(?:,|$)', attrib):
        if val.startswith('"'):
            val = val[1:-1]
        else:
            info[key] = val

    return info


def urshift(val, n):
    if val >= 0:
        return val >> n
    return val + 4294967296 >> n


def decode_png(png_data):
    header = png_data[8:]
    if png_data[:8] != b'\x89PNG\r\n\x1a\n' or (header[4:8] != 'IHDR'):
        raise IOError('Not a valid PNG file.')
    int_map = {1:'>B',  2:'>H',  4:'>I'}
    unpack_integer = lambda x: compat_struct_unpack(int_map[len(x)], x)[0]
    chunks = []
    while header:
        length = unpack_integer(header[:4])
        header = header[4:]
        chunk_type = header[:4]
        header = header[4:]
        chunk_data = header[:length]
        header = header[length:]
        header = header[4:]
        chunks.append({'type':chunk_type, 
         'length':length, 
         'data':chunk_data})

    ihdr = chunks[0]['data']
    width = unpack_integer(ihdr[:4])
    height = unpack_integer(ihdr[4:8])
    idat = ''
    for chunk in chunks:
        if chunk['type'] == 'IDAT':
            idat += chunk['data']

    if not idat:
        raise IOError('Unable to read PNG data.')
    decompressed_data = bytearray(zlib.decompress(idat))
    stride = width * 3
    pixels = []

    def _get_pixel(idx):
        x = idx % stride
        y = idx // stride
        return pixels[y][x]

    for y in range(height):
        basePos = y * (1 + stride)
        filter_type = decompressed_data[basePos]
        current_row = []
        pixels.append(current_row)
        for x in range(stride):
            color = decompressed_data[(1 + basePos + x)]
            basex = y * stride + x
            left = 0
            up = 0
            if x > 2:
                left = _get_pixel(basex - 3)
            else:
                if y > 0:
                    up = _get_pixel(basex - stride)
                if filter_type == 1:
                    color = color + left & 255
                elif filter_type == 2:
                    color = color + up & 255
                elif filter_type == 3:
                    color = color + (left + up >> 1) & 255
                elif filter_type == 4:
                    a = left
                    b = up
                    c = 0
                    if x > 2:
                        if y > 0:
                            c = _get_pixel(basex - stride - 3)
                    p = a + b - c
                    pa = abs(p - a)
                    pb = abs(p - b)
                    pc = abs(p - c)
                    if pa <= pb and pa <= pc:
                        color = color + a & 255
                    elif pb <= pc:
                        color = color + b & 255
                    else:
                        color = color + c & 255
                current_row.append(color)

    return (
     width, height, pixels)


def write_xattr(path, key, value):
    try:
        import xattr
        if hasattr(xattr, 'set'):
            pyxattr_required_version = '0.5.0'
            if version_tuple(xattr.__version__) < version_tuple(pyxattr_required_version):
                raise XAttrUnavailableError('python-pyxattr is detected but is too old. youtube-dl requires %s or above while your version is %s. Falling back to other xattr implementations' % (
                 pyxattr_required_version, xattr.__version__))
            setxattr = xattr.set
        else:
            setxattr = xattr.setxattr
        try:
            setxattr(path, key, value)
        except EnvironmentError as e:
            try:
                raise XAttrMetadataError(e.errno, e.strerror)
            finally:
                e = None
                del e

    except ImportError:
        if compat_os_name == 'nt':
            assert ':' not in key
            assert os.path.exists(path)
            ads_fn = path + ':' + key
            try:
                with open(ads_fn, 'wb') as f:
                    f.write(value)
            except EnvironmentError as e:
                try:
                    raise XAttrMetadataError(e.errno, e.strerror)
                finally:
                    e = None
                    del e

        else:
            user_has_setfattr = check_executable('setfattr', ['--version'])
            user_has_xattr = check_executable('xattr', ['-h'])
            if user_has_setfattr or user_has_xattr:
                value = value.decode('utf-8')
                if user_has_setfattr:
                    executable = 'setfattr'
                    opts = ['-n', key, '-v', value]
                elif user_has_xattr:
                    executable = 'xattr'
                    opts = ['-w', key, value]
                cmd = [
                 encodeFilename(executable, True)] + [encodeArgument(o) for o in opts] + [encodeFilename(path, True)]
                try:
                    p = subprocess.Popen(cmd,
                      stdout=(subprocess.PIPE), stderr=(subprocess.PIPE), stdin=(subprocess.PIPE))
                except EnvironmentError as e:
                    try:
                        raise XAttrMetadataError(e.errno, e.strerror)
                    finally:
                        e = None
                        del e

                stdout, stderr = p.communicate()
                stderr = stderr.decode('utf-8', 'replace')
                if p.returncode != 0:
                    raise XAttrMetadataError(p.returncode, stderr)
            elif sys.platform.startswith('linux'):
                raise XAttrUnavailableError("Couldn't find a tool to set the xattrs. Install either the python 'pyxattr' or 'xattr' modules, or the GNU 'attr' package (which contains the 'setfattr' tool).")
            else:
                raise XAttrUnavailableError("Couldn't find a tool to set the xattrs. Install either the python 'xattr' module, or the 'xattr' binary.")


def random_birthday(year_field, month_field, day_field):
    start_date = datetime.date(1950, 1, 1)
    end_date = datetime.date(1995, 12, 31)
    offset = random.randint(0, (end_date - start_date).days)
    random_date = start_date + datetime.timedelta(offset)
    return {year_field: str(random_date.year), 
     month_field: str(random_date.month), 
     day_field: str(random_date.day)}


def clean_podcast_url(url):
    return re.sub('(?x)\n        (?:\n            (?:\n                chtbl\\.com/track|\n                media\\.blubrry\\.com| # https://create.blubrry.com/resources/podcast-media-download-statistics/getting-started/\n                play\\.podtrac\\.com\n            )/[^/]+|\n            (?:dts|www)\\.podtrac\\.com/(?:pts/)?redirect\\.[0-9a-z]{3,4}| # http://analytics.podtrac.com/how-to-measure\n            flex\\.acast\\.com|\n            pd(?:\n                cn\\.co| # https://podcorn.com/analytics-prefix/\n                st\\.fm # https://podsights.com/docs/\n            )/e\n        )/', '', url)